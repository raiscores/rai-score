{
  "aggregate": {
    "max_possible_score": 14,
    "percent_score": 28.6,
    "star_display": "★★",
    "star_rating": 2,
    "total_score": 4
  },
  "company": "American Family Insurance",
  "company_slug": "american-family-insurance",
  "evidence_breakdown": {
    "by_type": {
      "NARRATIVE": 5,
      "OPERATIONAL": 0,
      "POLICY": 9
    }
  },
  "pillar_scores": {
    "explainability": {
      "best_evidence_type": "POLICY",
      "display_name": "Explainability",
      "evidence_count": 1,
      "findings": "A third-party analysis notes the need for AI systems to be explainable. It also states that AI systems should be aligned with human judgment.",
      "max_score": 2,
      "path_to_improvement": "Publish user-facing explanation interfaces or documented appeal workflows.",
      "relevant_sources": [
        {
          "artifact_type": "other",
          "source_id": "src_007",
          "source_tier": "third_party",
          "summary": "This third-party analysis of American Family's AI use cases provides evidence for **explainability**, **governance**, and **transparency**. The report highlights a policy commitment to AI governance, stating it is foundational due to potential harm. It also indicates transparency through mentions of AI capabilities, applications, and the use of machine learning and computer vision for automation, while also noting the need for AI systems to be explainable and aligned with human judgment.",
          "title": "Artificial Intelligence at American Family Insurance Group",
          "url": "https://emerj.com/artificial-intelligence-at-american-family-insurance-group"
        }
      ],
      "score": 1,
      "source_count": 1
    },
    "external_accountability": {
      "best_evidence_type": null,
      "display_name": "Public Commitments & External Audits",
      "evidence_count": 0,
      "findings": null,
      "max_score": 2,
      "path_to_improvement": "Obtain external validation of AI practices or require vendor certifications.",
      "relevant_sources": [],
      "score": 0,
      "source_count": 0
    },
    "fairness": {
      "best_evidence_type": null,
      "display_name": "Fairness & Bias Mitigation",
      "evidence_count": 0,
      "findings": null,
      "max_score": 2,
      "path_to_improvement": "Document bias testing procedures or vendor AI fairness requirements.",
      "relevant_sources": [],
      "score": 0,
      "source_count": 0
    },
    "governance": {
      "best_evidence_type": "POLICY",
      "display_name": "Governance & Accountability",
      "evidence_count": 8,
      "findings": "The company outlines a commitment to responsible AI use, a data governance framework, and adherence to applicable regulations. It describes a structured approach and oversight for AI/ML research, including a strategic approach to funding and collaboration. A policy commitment to AI governance is highlighted as foundational, and a funded academic project indicates a structured approach and accountability for AI initiatives aimed at mitigating inequality.",
      "max_score": 2,
      "path_to_improvement": "Name an AI governance body with defined mandate covering all AI use.",
      "relevant_sources": [
        {
          "artifact_type": "policy",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This company-owned policy document, \"Responsible Data and AI,\" provides evidence for the **governance** and **privacy** pillars. It supports governance by outlining the company's commitment to responsible AI use, a data governance framework, and adherence to applicable regulations. The policy also supports privacy by describing security measures to safeguard AI systems, implying a focus on data protection.",
          "title": "Responsible Data and AI",
          "url": "https://amfam.com/about/sustainable-business-framework/responsible-data-and-ai"
        },
        {
          "artifact_type": "other",
          "source_id": "src_003",
          "source_tier": "third_party",
          "summary": "This company-owned research website, \"Machine Learning Research Group,\" provides evidence for the **governance** pillar of responsible AI. The description of the group's aim and activities in AI/ML research and exploration indicates a structured approach and oversight of their AI initiatives.",
          "title": "Machine Learning Research Group",
          "url": "https://ai-ml-amfam.com"
        },
        {
          "artifact_type": "other",
          "source_id": "src_006",
          "source_tier": "third_party",
          "summary": "The \"American Family Funding Initiative\" page provides evidence for the **governance** pillar of responsible AI. This is supported by the description of a strategic approach to AI research funding and collaboration, which indicates governance over research direction and impact.",
          "title": "American Family Funding Initiative",
          "url": "https://dsi.wisc.edu/initiatives/research-amfam"
        },
        {
          "artifact_type": "other",
          "source_id": "src_007",
          "source_tier": "third_party",
          "summary": "This third-party analysis of American Family's AI use cases provides evidence for **explainability**, **governance**, and **transparency**. The report highlights a policy commitment to AI governance, stating it is foundational due to potential harm. It also indicates transparency through mentions of AI capabilities, applications, and the use of machine learning and computer vision for automation, while also noting the need for AI systems to be explainable and aligned with human judgment.",
          "title": "Artificial Intelligence at American Family Insurance Group",
          "url": "https://emerj.com/artificial-intelligence-at-american-family-insurance-group"
        },
        {
          "artifact_type": "technical_paper",
          "source_id": "src_010",
          "source_tier": "third_party",
          "summary": "This technical paper, \"External Academic Research on Mitigating AI Inequality,\" provides evidence for the **governance** pillar of responsible AI. The paper details a funded academic project by American Family Insurance's research group, which indicates a structured approach and accountability for AI initiatives aimed at mitigating inequality in AI decision-making. This project focuses on reducing unfairness in algorithmic responses and developing optimization methods to lessen the response quality gap between dominant and minority groups.",
          "title": "External Academic Research on Mitigating AI Inequality",
          "url": "https://ai-ml-amfam.com/external-research"
        }
      ],
      "score": 1,
      "source_count": 5
    },
    "oversight": {
      "best_evidence_type": null,
      "display_name": "Human Oversight & Accountability",
      "evidence_count": 0,
      "findings": null,
      "max_score": 2,
      "path_to_improvement": "Document human review processes for AI-assisted decisions (built or vendor AI).",
      "relevant_sources": [],
      "score": 0,
      "source_count": 0
    },
    "privacy": {
      "best_evidence_type": "POLICY",
      "display_name": "Privacy & Security",
      "evidence_count": 1,
      "findings": "A company-owned policy document describes security measures to safeguard AI systems. This policy implies a focus on data protection.",
      "max_score": 2,
      "path_to_improvement": "Publish AI-specific privacy impact assessments or data handling procedures.",
      "relevant_sources": [
        {
          "artifact_type": "policy",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This company-owned policy document, \"Responsible Data and AI,\" provides evidence for the **governance** and **privacy** pillars. It supports governance by outlining the company's commitment to responsible AI use, a data governance framework, and adherence to applicable regulations. The policy also supports privacy by describing security measures to safeguard AI systems, implying a focus on data protection.",
          "title": "Responsible Data and AI",
          "url": "https://amfam.com/about/sustainable-business-framework/responsible-data-and-ai"
        }
      ],
      "score": 1,
      "source_count": 1
    },
    "transparency": {
      "best_evidence_type": "POLICY",
      "display_name": "Transparency",
      "evidence_count": 7,
      "findings": "A third-party analysis mentions the company's AI capabilities and applications. It also references the use of machine learning and computer vision for automation.",
      "max_score": 2,
      "path_to_improvement": "Publish detailed documentation (model cards, system specs) for AI systems deployed.",
      "relevant_sources": [
        {
          "artifact_type": "other",
          "source_id": "src_007",
          "source_tier": "third_party",
          "summary": "This third-party analysis of American Family's AI use cases provides evidence for **explainability**, **governance**, and **transparency**. The report highlights a policy commitment to AI governance, stating it is foundational due to potential harm. It also indicates transparency through mentions of AI capabilities, applications, and the use of machine learning and computer vision for automation, while also noting the need for AI systems to be explainable and aligned with human judgment.",
          "title": "Artificial Intelligence at American Family Insurance Group",
          "url": "https://emerj.com/artificial-intelligence-at-american-family-insurance-group"
        }
      ],
      "score": 1,
      "source_count": 1
    }
  },
  "published_at": "2026-02-23T21:42:57Z",
  "run_id": "20260202_203035_c1fc",
  "schema_version": "1.0",
  "summary": {
    "key_gaps": [
      "Fairness & Bias Mitigation",
      "Human Oversight & Accountability",
      "Public Commitments & External Audits"
    ],
    "key_strengths": [],
    "overall_findings": "Drawing from 10 publicly available sources, American Family Insurance's published materials address 4 of 7 evaluated responsible AI pillars, all at the policy level. For instance, governance materials outline the company's commitment to responsible AI use, while privacy documentation describes security measures to safeguard AI systems. Additionally, transparency disclosures mention AI capabilities and applications, and explainability materials note the need for AI systems to be aligned with human judgment. No qualifying public evidence was found for fairness, oversight, and 1 additional pillar.",
    "pillars_operational": 0,
    "pillars_policy_only": 4,
    "pillars_with_evidence": 4,
    "pillars_without_evidence": 3,
    "total_evidence_items": 14,
    "total_sources_used": 5
  }
}
