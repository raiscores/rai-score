{
  "aggregate": {
    "max_possible_score": 14,
    "percent_score": 42.9,
    "star_display": "★★",
    "star_rating": 2,
    "total_score": 6
  },
  "company": "Stryker",
  "company_slug": "stryker",
  "evidence_breakdown": {
    "by_type": {
      "NARRATIVE": 0,
      "OPERATIONAL": 2,
      "POLICY": 19
    }
  },
  "pillar_scores": {
    "explainability": {
      "best_evidence_type": null,
      "display_name": "Explainability",
      "evidence_count": 0,
      "findings": null,
      "max_score": 2,
      "path_to_improvement": "Document how explanations are provided to users affected by AI decisions.",
      "relevant_sources": [],
      "score": 0,
      "source_count": 0
    },
    "external_accountability": {
      "best_evidence_type": "POLICY",
      "display_name": "Public Commitments & External Audits",
      "evidence_count": 1,
      "findings": "SEC filings acknowledge the company's practice of managing AI use in compliance with evolving laws and industry standards.",
      "max_score": 2,
      "path_to_improvement": "Publish third-party audit results, certifications, or regulatory compliance documentation.",
      "relevant_sources": [
        {
          "artifact_type": "sec_filing",
          "source_id": "src_008",
          "source_tier": "authority",
          "summary": "This SEC filing provides evidence for **governance**, **transparency**, and **external accountability**. It demonstrates governance through the Board's explicit oversight of cybersecurity risks and the CISO's regular updates to oversight bodies, as well as policies for managing AI use by employees and providers. Transparency is supported by mentions of exploring AI \"use cases\" and \"capabilities,\" while external accountability is evidenced by the company's acknowledgment of managing AI use in compliance with evolving laws and industry standards.",
          "title": "Form 10-K for year ended December 31, 2024",
          "url": "https://sec.gov/Archives/edgar/data/310764/000031076425000023/syk-20241231.htm"
        }
      ],
      "score": 1,
      "source_count": 1
    },
    "fairness": {
      "best_evidence_type": "POLICY",
      "display_name": "Fairness & Bias Mitigation",
      "evidence_count": 1,
      "findings": "Reports acknowledge concerns related to bias.",
      "max_score": 2,
      "path_to_improvement": "Publish bias testing results, outcome monitoring, or vendor fairness certifications.",
      "relevant_sources": [
        {
          "artifact_type": "other",
          "source_id": "src_006",
          "source_tier": "company_owned",
          "summary": "The \"Stryker 2023 Comprehensive Report\" provides evidence for fairness, governance, privacy, and transparency in responsible AI. This company-owned report supports governance by detailing the introduction of IT organization roles for AI data management and oversight, and by mentioning internal guidelines for generative AI use. It also supports privacy through a stated commitment to privacy in AI innovation and linking AI/data use to privacy practices. Transparency is evidenced by mentions of algorithms, software applications, and an AI-enabled platform, while fairness is implied through acknowledgments of bias concerns.",
          "title": "Stryker 2023 Comprehensive Report",
          "url": "https://stryker.com/content/dam/stryker/about/annual-review/2023/Stryker-2023-Comprehensive-Report.pdf"
        }
      ],
      "score": 1,
      "source_count": 1
    },
    "governance": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Governance & Accountability",
      "evidence_count": 16,
      "findings": "Reports detail the establishment of an AI Governance Committee and mention potential AI, ML, and deep learning applications, as well as the acquisition of AI technology. Policy documents describe the enterprise cybersecurity program, leveraging AI and ML, operating under established corporate policies and reporting structures. Reports also detail IT organization roles for AI data management and oversight, mention internal guidelines for generative AI use, and SEC filings describe Board oversight of cybersecurity risks and policies for managing AI use by employees and providers.",
      "max_score": 2,
      "path_to_improvement": null,
      "relevant_sources": [
        {
          "artifact_type": "other",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "The \"Stryker 2024 Comprehensive Report\" provides evidence for the **governance** pillar of responsible AI. The report details Stryker's establishment of an AI Governance Committee, demonstrating a formal mechanism for managing AI risk. Furthermore, the mention of potential AI, ML, and deep learning applications across their development portfolio and internal operations, alongside the acquisition of AI technology, indicates strategic decision-making and integration planning related to AI.",
          "title": "Stryker 2024 Comprehensive Report",
          "url": "https://stryker.com/content/dam/stryker/about/annual-review/2024/Stryker-2024-Comprehensive-Report.pdf"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_002",
          "source_tier": "company_owned",
          "summary": "This policy document, \"Cybersecurity governance overview,\" provides evidence for the **governance** pillar of responsible AI. It supports this pillar by describing how Stryker's enterprise cybersecurity program, which leverages AI and ML for global protection, operates under established corporate policies and reporting structures, indicating a governed approach to AI use.",
          "title": "Cybersecurity governance overview",
          "url": "https://stryker.com/us/en/about/governance/security.html"
        },
        {
          "artifact_type": "help_page",
          "source_id": "src_003",
          "source_tier": "company_owned",
          "summary": "The \"Stryker Endoscopy AI and Machine Learning Software\" help page provides evidence for the **governance** pillar. This is because the document describes Stryker's endoscopy products as being designed with AI/ML concepts, indicating a deliberate and structured approach to their AI development.",
          "title": "Stryker Endoscopy AI and Machine Learning Software",
          "url": "https://stryker.com/us/en/endoscopy.html"
        },
        {
          "artifact_type": "other",
          "source_id": "src_006",
          "source_tier": "company_owned",
          "summary": "The \"Stryker 2023 Comprehensive Report\" provides evidence for fairness, governance, privacy, and transparency in responsible AI. This company-owned report supports governance by detailing the introduction of IT organization roles for AI data management and oversight, and by mentioning internal guidelines for generative AI use. It also supports privacy through a stated commitment to privacy in AI innovation and linking AI/data use to privacy practices. Transparency is evidenced by mentions of algorithms, software applications, and an AI-enabled platform, while fairness is implied through acknowledgments of bias concerns.",
          "title": "Stryker 2023 Comprehensive Report",
          "url": "https://stryker.com/content/dam/stryker/about/annual-review/2023/Stryker-2023-Comprehensive-Report.pdf"
        },
        {
          "artifact_type": "sec_filing",
          "source_id": "src_008",
          "source_tier": "authority",
          "summary": "This SEC filing provides evidence for **governance**, **transparency**, and **external accountability**. It demonstrates governance through the Board's explicit oversight of cybersecurity risks and the CISO's regular updates to oversight bodies, as well as policies for managing AI use by employees and providers. Transparency is supported by mentions of exploring AI \"use cases\" and \"capabilities,\" while external accountability is evidenced by the company's acknowledgment of managing AI use in compliance with evolving laws and industry standards.",
          "title": "Form 10-K for year ended December 31, 2024",
          "url": "https://sec.gov/Archives/edgar/data/310764/000031076425000023/syk-20241231.htm"
        }
      ],
      "score": 2,
      "source_count": 5
    },
    "oversight": {
      "best_evidence_type": null,
      "display_name": "Human Oversight & Accountability",
      "evidence_count": 0,
      "findings": null,
      "max_score": 2,
      "path_to_improvement": "Document human review processes for AI-assisted decisions (built or vendor AI).",
      "relevant_sources": [],
      "score": 0,
      "source_count": 0
    },
    "privacy": {
      "best_evidence_type": "POLICY",
      "display_name": "Privacy & Security",
      "evidence_count": 3,
      "findings": "Reports state a commitment to privacy in AI innovation. They also reference linking AI and data use to privacy practices.",
      "max_score": 2,
      "path_to_improvement": "Publish AI-specific privacy impact assessments or data handling procedures.",
      "relevant_sources": [
        {
          "artifact_type": "other",
          "source_id": "src_006",
          "source_tier": "company_owned",
          "summary": "The \"Stryker 2023 Comprehensive Report\" provides evidence for fairness, governance, privacy, and transparency in responsible AI. This company-owned report supports governance by detailing the introduction of IT organization roles for AI data management and oversight, and by mentioning internal guidelines for generative AI use. It also supports privacy through a stated commitment to privacy in AI innovation and linking AI/data use to privacy practices. Transparency is evidenced by mentions of algorithms, software applications, and an AI-enabled platform, while fairness is implied through acknowledgments of bias concerns.",
          "title": "Stryker 2023 Comprehensive Report",
          "url": "https://stryker.com/content/dam/stryker/about/annual-review/2023/Stryker-2023-Comprehensive-Report.pdf"
        }
      ],
      "score": 1,
      "source_count": 1
    },
    "transparency": {
      "best_evidence_type": "POLICY",
      "display_name": "Transparency",
      "evidence_count": 5,
      "findings": "Reports reference the company's algorithms, software applications, and an AI-enabled platform. SEC filings also mention exploring AI \"use cases\" and \"capabilities.\"",
      "max_score": 2,
      "path_to_improvement": "Publish detailed documentation (model cards, system specs) for AI systems deployed.",
      "relevant_sources": [
        {
          "artifact_type": "other",
          "source_id": "src_006",
          "source_tier": "company_owned",
          "summary": "The \"Stryker 2023 Comprehensive Report\" provides evidence for fairness, governance, privacy, and transparency in responsible AI. This company-owned report supports governance by detailing the introduction of IT organization roles for AI data management and oversight, and by mentioning internal guidelines for generative AI use. It also supports privacy through a stated commitment to privacy in AI innovation and linking AI/data use to privacy practices. Transparency is evidenced by mentions of algorithms, software applications, and an AI-enabled platform, while fairness is implied through acknowledgments of bias concerns.",
          "title": "Stryker 2023 Comprehensive Report",
          "url": "https://stryker.com/content/dam/stryker/about/annual-review/2023/Stryker-2023-Comprehensive-Report.pdf"
        },
        {
          "artifact_type": "sec_filing",
          "source_id": "src_008",
          "source_tier": "authority",
          "summary": "This SEC filing provides evidence for **governance**, **transparency**, and **external accountability**. It demonstrates governance through the Board's explicit oversight of cybersecurity risks and the CISO's regular updates to oversight bodies, as well as policies for managing AI use by employees and providers. Transparency is supported by mentions of exploring AI \"use cases\" and \"capabilities,\" while external accountability is evidenced by the company's acknowledgment of managing AI use in compliance with evolving laws and industry standards.",
          "title": "Form 10-K for year ended December 31, 2024",
          "url": "https://sec.gov/Archives/edgar/data/310764/000031076425000023/syk-20241231.htm"
        }
      ],
      "score": 1,
      "source_count": 2
    }
  },
  "published_at": "2026-02-23T21:59:00Z",
  "run_id": "20260203_025330_b979",
  "schema_version": "1.0",
  "summary": {
    "key_gaps": [
      "Explainability",
      "Human Oversight & Accountability"
    ],
    "key_strengths": [
      "Governance & Accountability"
    ],
    "overall_findings": "Stryker's public disclosures detail the establishment of an AI Governance Committee, an operational practice within the governance pillar. Overall, 5 of 7 evaluated responsible AI pillars have documented evidence in the company's published materials. Policy-level evidence is present for transparency, fairness, privacy, and external accountability, with disclosures referencing algorithms and an AI-enabled platform, acknowledging bias concerns, and stating a commitment to privacy in AI innovation. No qualifying public evidence was found for explainability or oversight, based on a review of 9 publicly available sources.",
    "pillars_operational": 1,
    "pillars_policy_only": 4,
    "pillars_with_evidence": 5,
    "pillars_without_evidence": 2,
    "total_evidence_items": 21,
    "total_sources_used": 5
  }
}
