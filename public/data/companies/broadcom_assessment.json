{
  "aggregate": {
    "max_possible_score": 14,
    "percent_score": 57.1,
    "star_display": "★★★",
    "star_rating": 3,
    "total_score": 8
  },
  "company": "Broadcom",
  "company_slug": "broadcom",
  "evidence_breakdown": {
    "by_type": {
      "NARRATIVE": 1,
      "OPERATIONAL": 2,
      "POLICY": 20
    }
  },
  "pillar_scores": {
    "explainability": {
      "best_evidence_type": null,
      "display_name": "Explainability",
      "evidence_count": 0,
      "findings": null,
      "max_score": 2,
      "path_to_improvement": "Document how explanations are provided to users affected by AI decisions.",
      "relevant_sources": [],
      "score": 0,
      "source_count": 0
    },
    "external_accountability": {
      "best_evidence_type": "POLICY",
      "display_name": "Public Commitments & External Audits",
      "evidence_count": 4,
      "findings": "A technical paper discusses the EU AI Act's mandates for risk management, data governance, and human oversight, supporting external accountability. The paper also discusses an Executive Order directing new standards for AI safety and security, further supporting external accountability.",
      "max_score": 2,
      "path_to_improvement": "Publish third-party audit results, certifications, or regulatory compliance documentation.",
      "relevant_sources": [
        {
          "artifact_type": "technical_paper",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This technical paper from Broadcom provides evidence for external_accountability, governance, oversight, privacy, and transparency. It discusses the EU AI Act's mandates for risk management, data governance, and human oversight, as well as an Executive Order directing new standards for AI safety and security, supporting external_accountability and oversight. The paper also highlights a privacy-first approach, AI model governance for production approval, and the need for AI-specific governance, policies, and processes, demonstrating evidence for governance and privacy.",
          "title": "Broadcom: Realizing GenAI Value in Regulated Industries",
          "url": "https://docs.broadcom.com/doc/idc-realizing-the-value-of-genai-in-regulated-industries-while-controlling-costs-and-risks"
        }
      ],
      "score": 1,
      "source_count": 1
    },
    "fairness": {
      "best_evidence_type": null,
      "display_name": "Fairness & Bias Mitigation",
      "evidence_count": 0,
      "findings": null,
      "max_score": 2,
      "path_to_improvement": "Document bias testing procedures or vendor AI fairness requirements.",
      "relevant_sources": [],
      "score": 0,
      "source_count": 0
    },
    "governance": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Governance & Accountability",
      "evidence_count": 21,
      "findings": "Broadcom's technical papers discuss EU AI Act mandates for risk management and data governance, highlighting AI model governance for production approval and the need for AI-specific governance, policies, and processes. Documentation describes the use of AI/ML for threat detection and remediation, implying governance over these systems. A blog post further details the use of AI SBOMs for risk assessment and compliance, mentioning governance frameworks like OPEA and highlighting tools like Model Guard and Prompt Guard.",
      "max_score": 2,
      "path_to_improvement": null,
      "relevant_sources": [
        {
          "artifact_type": "technical_paper",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This technical paper from Broadcom provides evidence for external_accountability, governance, oversight, privacy, and transparency. It discusses the EU AI Act's mandates for risk management, data governance, and human oversight, as well as an Executive Order directing new standards for AI safety and security, supporting external_accountability and oversight. The paper also highlights a privacy-first approach, AI model governance for production approval, and the need for AI-specific governance, policies, and processes, demonstrating evidence for governance and privacy.",
          "title": "Broadcom: Realizing GenAI Value in Regulated Industries",
          "url": "https://docs.broadcom.com/doc/idc-realizing-the-value-of-genai-in-regulated-industries-while-controlling-costs-and-risks"
        },
        {
          "artifact_type": "technical_paper",
          "source_id": "src_002",
          "source_tier": "company_owned",
          "summary": "This technical paper, \"Broadcom Cloud Security Maturity: Governance and AI Automation,\" provides evidence for **governance**, **oversight**, and **transparency**. The document describes Broadcom's use of AI/ML for threat detection and remediation, implying governance over these systems and their application in enforcing data governance. Furthermore, it details AI execution alongside human oversight for critical security alerts, demonstrating operational processes and mechanisms for transparency in automated findings.",
          "title": "Broadcom Cloud Security Maturity: Governance and AI Automation",
          "url": "https://docs.broadcom.com/doc/cstr-1-en"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_003",
          "source_tier": "company_owned",
          "summary": "This Broadcom blog post provides evidence for the **governance** and **transparency** pillars of responsible AI. The post details the use of AI SBOMs for risk assessment and compliance, mentions governance frameworks like OPEA, and highlights tools like Model Guard and Prompt Guard, all of which demonstrate a commitment to oversight and control. Furthermore, the emphasis on transparency through AI SBOMs and the discussion of common use cases for generative AI services support the transparency pillar by detailing how AI systems' capabilities and deployments are made clear.",
          "title": "Broadcom: Open-Source AI Principles and Governance",
          "url": "https://news.broadcom.com/artificial-intelligence/ai-open-source-projects-that-should-be-on-your-radar"
        }
      ],
      "score": 2,
      "source_count": 3
    },
    "oversight": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Human Oversight & Accountability",
      "evidence_count": 3,
      "findings": "Broadcom's technical papers discuss the EU AI Act's mandates for human oversight and an Executive Order directing new standards for AI safety and security, supporting oversight. These papers also highlight AI model governance for production approval. Additionally, documentation details AI execution alongside human oversight for critical security alerts.",
      "max_score": 2,
      "path_to_improvement": null,
      "relevant_sources": [
        {
          "artifact_type": "technical_paper",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This technical paper from Broadcom provides evidence for external_accountability, governance, oversight, privacy, and transparency. It discusses the EU AI Act's mandates for risk management, data governance, and human oversight, as well as an Executive Order directing new standards for AI safety and security, supporting external_accountability and oversight. The paper also highlights a privacy-first approach, AI model governance for production approval, and the need for AI-specific governance, policies, and processes, demonstrating evidence for governance and privacy.",
          "title": "Broadcom: Realizing GenAI Value in Regulated Industries",
          "url": "https://docs.broadcom.com/doc/idc-realizing-the-value-of-genai-in-regulated-industries-while-controlling-costs-and-risks"
        },
        {
          "artifact_type": "technical_paper",
          "source_id": "src_002",
          "source_tier": "company_owned",
          "summary": "This technical paper, \"Broadcom Cloud Security Maturity: Governance and AI Automation,\" provides evidence for **governance**, **oversight**, and **transparency**. The document describes Broadcom's use of AI/ML for threat detection and remediation, implying governance over these systems and their application in enforcing data governance. Furthermore, it details AI execution alongside human oversight for critical security alerts, demonstrating operational processes and mechanisms for transparency in automated findings.",
          "title": "Broadcom Cloud Security Maturity: Governance and AI Automation",
          "url": "https://docs.broadcom.com/doc/cstr-1-en"
        }
      ],
      "score": 2,
      "source_count": 2
    },
    "privacy": {
      "best_evidence_type": "POLICY",
      "display_name": "Privacy & Security",
      "evidence_count": 3,
      "findings": "A technical paper highlights Broadcom's privacy-first approach in its AI practices.",
      "max_score": 2,
      "path_to_improvement": "Publish AI-specific privacy impact assessments or data handling procedures.",
      "relevant_sources": [
        {
          "artifact_type": "technical_paper",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This technical paper from Broadcom provides evidence for external_accountability, governance, oversight, privacy, and transparency. It discusses the EU AI Act's mandates for risk management, data governance, and human oversight, as well as an Executive Order directing new standards for AI safety and security, supporting external_accountability and oversight. The paper also highlights a privacy-first approach, AI model governance for production approval, and the need for AI-specific governance, policies, and processes, demonstrating evidence for governance and privacy.",
          "title": "Broadcom: Realizing GenAI Value in Regulated Industries",
          "url": "https://docs.broadcom.com/doc/idc-realizing-the-value-of-genai-in-regulated-industries-while-controlling-costs-and-risks"
        }
      ],
      "score": 1,
      "source_count": 1
    },
    "transparency": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Transparency",
      "evidence_count": 7,
      "findings": "Broadcom's documentation details AI execution alongside human oversight for critical security alerts, demonstrating mechanisms for transparency in automated findings. A blog post further emphasizes transparency through AI SBOMs and discusses common use cases for generative AI services, outlining how AI systems' capabilities and deployments are made clear.",
      "max_score": 2,
      "path_to_improvement": null,
      "relevant_sources": [
        {
          "artifact_type": "technical_paper",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This technical paper from Broadcom provides evidence for external_accountability, governance, oversight, privacy, and transparency. It discusses the EU AI Act's mandates for risk management, data governance, and human oversight, as well as an Executive Order directing new standards for AI safety and security, supporting external_accountability and oversight. The paper also highlights a privacy-first approach, AI model governance for production approval, and the need for AI-specific governance, policies, and processes, demonstrating evidence for governance and privacy.",
          "title": "Broadcom: Realizing GenAI Value in Regulated Industries",
          "url": "https://docs.broadcom.com/doc/idc-realizing-the-value-of-genai-in-regulated-industries-while-controlling-costs-and-risks"
        },
        {
          "artifact_type": "technical_paper",
          "source_id": "src_002",
          "source_tier": "company_owned",
          "summary": "This technical paper, \"Broadcom Cloud Security Maturity: Governance and AI Automation,\" provides evidence for **governance**, **oversight**, and **transparency**. The document describes Broadcom's use of AI/ML for threat detection and remediation, implying governance over these systems and their application in enforcing data governance. Furthermore, it details AI execution alongside human oversight for critical security alerts, demonstrating operational processes and mechanisms for transparency in automated findings.",
          "title": "Broadcom Cloud Security Maturity: Governance and AI Automation",
          "url": "https://docs.broadcom.com/doc/cstr-1-en"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_003",
          "source_tier": "company_owned",
          "summary": "This Broadcom blog post provides evidence for the **governance** and **transparency** pillars of responsible AI. The post details the use of AI SBOMs for risk assessment and compliance, mentions governance frameworks like OPEA, and highlights tools like Model Guard and Prompt Guard, all of which demonstrate a commitment to oversight and control. Furthermore, the emphasis on transparency through AI SBOMs and the discussion of common use cases for generative AI services support the transparency pillar by detailing how AI systems' capabilities and deployments are made clear.",
          "title": "Broadcom: Open-Source AI Principles and Governance",
          "url": "https://news.broadcom.com/artificial-intelligence/ai-open-source-projects-that-should-be-on-your-radar"
        }
      ],
      "score": 2,
      "source_count": 3
    }
  },
  "published_at": "2026-02-23T21:45:40Z",
  "run_id": "20260128_161132_cd23",
  "schema_version": "1.0",
  "summary": {
    "key_gaps": [
      "Fairness & Bias Mitigation",
      "Explainability"
    ],
    "key_strengths": [
      "Transparency",
      "Human Oversight & Accountability",
      "Governance & Accountability"
    ],
    "overall_findings": "Broadcom's public disclosures detail operational practices for transparency, including documentation of AI execution alongside human oversight for critical security alerts, and for governance, highlighting AI model governance for production approval. These materials address 5 of 7 evaluated responsible AI pillars, with oversight also documented through discussions of the EU AI Act's mandates for human oversight. Additionally, privacy is addressed through a privacy-first approach, and external accountability is supported by discussions of the EU AI Act's mandates for risk management and data governance, drawing from 3 publicly available sources. No qualifying public evidence was found for fairness or explainability.",
    "pillars_operational": 3,
    "pillars_policy_only": 2,
    "pillars_with_evidence": 5,
    "pillars_without_evidence": 2,
    "total_evidence_items": 23,
    "total_sources_used": 3
  }
}
