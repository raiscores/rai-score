{
  "aggregate": {
    "max_possible_score": 14,
    "percent_score": 28.6,
    "star_display": "★★",
    "star_rating": 2,
    "total_score": 4
  },
  "company": "Progressive",
  "company_slug": "progressive",
  "evidence_breakdown": {
    "by_type": {
      "NARRATIVE": 15,
      "OPERATIONAL": 4,
      "POLICY": 11
    }
  },
  "pillar_scores": {
    "explainability": {
      "best_evidence_type": "NARRATIVE",
      "display_name": "Explainability",
      "evidence_count": 1,
      "findings": "Technical papers acknowledge the 'black box' nature of AI decisions.",
      "max_score": 2,
      "path_to_improvement": "Document how explanations are provided to users affected by AI decisions.",
      "relevant_sources": [
        {
          "artifact_type": "technical_paper",
          "source_id": "src_007",
          "source_tier": "third_party",
          "summary": "This third-party technical paper, \"Progressive AI Strategy: Analysis of Dominance in Insurance AI,\" provides evidence for several responsible AI pillars. It supports **governance** by detailing Progressive's AI Governance Program (AIS Program), a formal framework covering the full insurance lifecycle, committee-based oversight, and partnerships for model development. Evidence for **fairness** and **external accountability** is found in the description of bias testing procedures, fairness compliance mechanisms, and discussions of algorithmic bias, disparate impact, and compliance requirements for bias analysis and mitigation. The paper also touches upon **transparency** through descriptions of AI use, features, and capabilities, and **explainability** by acknowledging the \"black box\" nature of AI decisions. Finally, the mention of the program being subject to regulatory review and audit supports **external accountability**.",
          "title": "Progressive AI Strategy: Analysis of Dominance in Insurance AI",
          "url": "https://klover.ai/progressive-ai-strategy-analysis-of-dominance-in-insurance-ai"
        }
      ],
      "score": 0,
      "source_count": 1
    },
    "external_accountability": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Public Commitments & External Audits",
      "evidence_count": 3,
      "findings": "Technical papers describe bias testing procedures, fairness compliance mechanisms, and discussions of algorithmic bias, disparate impact, and compliance requirements for bias analysis and mitigation. They also mention the AI program being subject to regulatory review and audit.",
      "max_score": 2,
      "path_to_improvement": "Publish third-party audit results, certifications, or regulatory compliance documentation.",
      "relevant_sources": [
        {
          "artifact_type": "technical_paper",
          "source_id": "src_007",
          "source_tier": "third_party",
          "summary": "This third-party technical paper, \"Progressive AI Strategy: Analysis of Dominance in Insurance AI,\" provides evidence for several responsible AI pillars. It supports **governance** by detailing Progressive's AI Governance Program (AIS Program), a formal framework covering the full insurance lifecycle, committee-based oversight, and partnerships for model development. Evidence for **fairness** and **external accountability** is found in the description of bias testing procedures, fairness compliance mechanisms, and discussions of algorithmic bias, disparate impact, and compliance requirements for bias analysis and mitigation. The paper also touches upon **transparency** through descriptions of AI use, features, and capabilities, and **explainability** by acknowledging the \"black box\" nature of AI decisions. Finally, the mention of the program being subject to regulatory review and audit supports **external accountability**.",
          "title": "Progressive AI Strategy: Analysis of Dominance in Insurance AI",
          "url": "https://klover.ai/progressive-ai-strategy-analysis-of-dominance-in-insurance-ai"
        }
      ],
      "score": 1,
      "source_count": 1
    },
    "fairness": {
      "best_evidence_type": "POLICY",
      "display_name": "Fairness & Bias Mitigation",
      "evidence_count": 3,
      "findings": "Technical papers describe bias testing procedures and fairness compliance mechanisms. They also discuss algorithmic bias, disparate impact, and compliance requirements for bias analysis and mitigation.",
      "max_score": 2,
      "path_to_improvement": "Publish bias testing results, outcome monitoring, or vendor fairness certifications.",
      "relevant_sources": [
        {
          "artifact_type": "technical_paper",
          "source_id": "src_007",
          "source_tier": "third_party",
          "summary": "This third-party technical paper, \"Progressive AI Strategy: Analysis of Dominance in Insurance AI,\" provides evidence for several responsible AI pillars. It supports **governance** by detailing Progressive's AI Governance Program (AIS Program), a formal framework covering the full insurance lifecycle, committee-based oversight, and partnerships for model development. Evidence for **fairness** and **external accountability** is found in the description of bias testing procedures, fairness compliance mechanisms, and discussions of algorithmic bias, disparate impact, and compliance requirements for bias analysis and mitigation. The paper also touches upon **transparency** through descriptions of AI use, features, and capabilities, and **explainability** by acknowledging the \"black box\" nature of AI decisions. Finally, the mention of the program being subject to regulatory review and audit supports **external accountability**.",
          "title": "Progressive AI Strategy: Analysis of Dominance in Insurance AI",
          "url": "https://klover.ai/progressive-ai-strategy-analysis-of-dominance-in-insurance-ai"
        }
      ],
      "score": 1,
      "source_count": 1
    },
    "governance": {
      "best_evidence_type": "POLICY",
      "display_name": "Governance & Accountability",
      "evidence_count": 15,
      "findings": "Proxy statements outline the board's assignment of AI oversight responsibilities to a Technology Committee, detailing its charter and responsibilities, and describing a review process for AI-related risks. Policy documents outline a commitment to responsible AI principles, detail AI use cases, and describe mechanisms for testing AI responsibly, including a framework for considering and mitigating biases. Reports and technical papers detail formal AI governance and risk management programs, including committee-based oversight, a formal framework covering the full insurance lifecycle, and partnerships for model development.",
      "max_score": 2,
      "path_to_improvement": "Name an AI governance body with defined mandate covering all AI use.",
      "relevant_sources": [
        {
          "artifact_type": "proxy_statement",
          "source_id": "src_001",
          "source_tier": "third_party",
          "summary": "This proxy statement provides evidence for the **governance** pillar of responsible AI. It demonstrates governance by outlining the board's assignment of AI oversight responsibilities to the Technology Committee and detailing the committee's charter and responsibilities related to technology strategies, including AI. The document also indicates governance through its description of a review process for AI-related risks and the approval of a scoring matrix and scenarios by a committee.",
          "title": "Progressive 2025 Proxy Statement",
          "url": "https://s202.q4cdn.com/605347829/files/doc_downloads/2025/ProxyStatement-2025.pdf"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_004",
          "source_tier": "company_owned",
          "summary": "This policy document, \"Progressive Artificial Intelligence and Your Privacy Policy,\" provides evidence for the **governance** pillar of responsible AI. It outlines Progressive's commitment to responsible AI principles, details AI use cases, and describes mechanisms for testing AI responsibly, including a framework for considering and mitigating biases.",
          "title": "Progressive Artificial Intelligence and Your Privacy Policy",
          "url": "https://progressive.com/support/legal/ai-policy"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_005",
          "source_tier": "third_party",
          "summary": "This policy document, Progressive's \"Progressive 2024 Corporate Sustainability Report,\" provides evidence for the **governance** and **transparency** pillars of Responsible AI. The report details Progressive's formal Responsible AI (RAI) governance and risk management program, which includes oversight by a named committee, demonstrating a commitment to structured AI management. Furthermore, the mention of an AI approach implies documentation of AI use, supporting the transparency pillar.",
          "title": "Progressive 2024 Corporate Sustainability Report",
          "url": "https://s202.q4cdn.com/605347829/files/doc_downloads/2025/09/progressive_2024corporate-sustainability-report.pdf"
        },
        {
          "artifact_type": "technical_paper",
          "source_id": "src_007",
          "source_tier": "third_party",
          "summary": "This third-party technical paper, \"Progressive AI Strategy: Analysis of Dominance in Insurance AI,\" provides evidence for several responsible AI pillars. It supports **governance** by detailing Progressive's AI Governance Program (AIS Program), a formal framework covering the full insurance lifecycle, committee-based oversight, and partnerships for model development. Evidence for **fairness** and **external accountability** is found in the description of bias testing procedures, fairness compliance mechanisms, and discussions of algorithmic bias, disparate impact, and compliance requirements for bias analysis and mitigation. The paper also touches upon **transparency** through descriptions of AI use, features, and capabilities, and **explainability** by acknowledging the \"black box\" nature of AI decisions. Finally, the mention of the program being subject to regulatory review and audit supports **external accountability**.",
          "title": "Progressive AI Strategy: Analysis of Dominance in Insurance AI",
          "url": "https://klover.ai/progressive-ai-strategy-analysis-of-dominance-in-insurance-ai"
        }
      ],
      "score": 1,
      "source_count": 4
    },
    "oversight": {
      "best_evidence_type": null,
      "display_name": "Human Oversight & Accountability",
      "evidence_count": 0,
      "findings": null,
      "max_score": 2,
      "path_to_improvement": "Document human review processes for AI-assisted decisions (built or vendor AI).",
      "relevant_sources": [],
      "score": 0,
      "source_count": 0
    },
    "privacy": {
      "best_evidence_type": "NARRATIVE",
      "display_name": "Privacy & Security",
      "evidence_count": 1,
      "findings": "Sources describe documented privacy practices in 1 source(s). Additional documentation references related practices.",
      "max_score": 2,
      "path_to_improvement": "Document data protection practices for AI systems, including vendor AI data handling.",
      "relevant_sources": [
        {
          "artifact_type": "technical_paper",
          "source_id": "src_007",
          "source_tier": "third_party",
          "summary": "This third-party technical paper, \"Progressive AI Strategy: Analysis of Dominance in Insurance AI,\" provides evidence for several responsible AI pillars. It supports **governance** by detailing Progressive's AI Governance Program (AIS Program), a formal framework covering the full insurance lifecycle, committee-based oversight, and partnerships for model development. Evidence for **fairness** and **external accountability** is found in the description of bias testing procedures, fairness compliance mechanisms, and discussions of algorithmic bias, disparate impact, and compliance requirements for bias analysis and mitigation. The paper also touches upon **transparency** through descriptions of AI use, features, and capabilities, and **explainability** by acknowledging the \"black box\" nature of AI decisions. Finally, the mention of the program being subject to regulatory review and audit supports **external accountability**.",
          "title": "Progressive AI Strategy: Analysis of Dominance in Insurance AI",
          "url": "https://klover.ai/progressive-ai-strategy-analysis-of-dominance-in-insurance-ai"
        }
      ],
      "score": 0,
      "source_count": 1
    },
    "transparency": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Transparency",
      "evidence_count": 17,
      "findings": "Reports imply documentation of AI use. Technical papers describe AI use, features, and capabilities.",
      "max_score": 2,
      "path_to_improvement": "Publish detailed documentation (model cards, system specs) for AI systems deployed.",
      "relevant_sources": [
        {
          "artifact_type": "policy",
          "source_id": "src_005",
          "source_tier": "third_party",
          "summary": "This policy document, Progressive's \"Progressive 2024 Corporate Sustainability Report,\" provides evidence for the **governance** and **transparency** pillars of Responsible AI. The report details Progressive's formal Responsible AI (RAI) governance and risk management program, which includes oversight by a named committee, demonstrating a commitment to structured AI management. Furthermore, the mention of an AI approach implies documentation of AI use, supporting the transparency pillar.",
          "title": "Progressive 2024 Corporate Sustainability Report",
          "url": "https://s202.q4cdn.com/605347829/files/doc_downloads/2025/09/progressive_2024corporate-sustainability-report.pdf"
        },
        {
          "artifact_type": "technical_paper",
          "source_id": "src_007",
          "source_tier": "third_party",
          "summary": "This third-party technical paper, \"Progressive AI Strategy: Analysis of Dominance in Insurance AI,\" provides evidence for several responsible AI pillars. It supports **governance** by detailing Progressive's AI Governance Program (AIS Program), a formal framework covering the full insurance lifecycle, committee-based oversight, and partnerships for model development. Evidence for **fairness** and **external accountability** is found in the description of bias testing procedures, fairness compliance mechanisms, and discussions of algorithmic bias, disparate impact, and compliance requirements for bias analysis and mitigation. The paper also touches upon **transparency** through descriptions of AI use, features, and capabilities, and **explainability** by acknowledging the \"black box\" nature of AI decisions. Finally, the mention of the program being subject to regulatory review and audit supports **external accountability**.",
          "title": "Progressive AI Strategy: Analysis of Dominance in Insurance AI",
          "url": "https://klover.ai/progressive-ai-strategy-analysis-of-dominance-in-insurance-ai"
        }
      ],
      "score": 1,
      "source_count": 2
    }
  },
  "published_at": "2026-02-23T21:57:54Z",
  "run_id": "20260203_013509_ef88",
  "schema_version": "1.0",
  "summary": {
    "key_gaps": [
      "Explainability",
      "Human Oversight & Accountability",
      "Privacy & Security"
    ],
    "key_strengths": [],
    "overall_findings": "Progressive's technical papers describe bias testing procedures and fairness compliance mechanisms, addressing the fairness pillar. Published materials also indicate that reports imply documentation of AI use and describe AI use, features, and capabilities for transparency, contributing to the 4 of 7 evaluated pillars with documented evidence. Governance is addressed through proxy statements that outline the board's assignment of AI oversight responsibilities to the Technology Committee, while external accountability is covered by technical papers detailing bias testing procedures and fairness compliance mechanisms. No qualifying public evidence was found for explainability, oversight, and 1 additional pillar, based on a review of 9 publicly available sources.",
    "pillars_operational": 0,
    "pillars_policy_only": 4,
    "pillars_with_evidence": 4,
    "pillars_without_evidence": 3,
    "total_evidence_items": 30,
    "total_sources_used": 4
  }
}
