{
  "aggregate": {
    "max_possible_score": 14,
    "percent_score": 57.1,
    "star_display": "★★★",
    "star_rating": 3,
    "total_score": 8
  },
  "company": "Paramount",
  "company_slug": "paramount-global",
  "evidence_breakdown": {
    "by_type": {
      "NARRATIVE": 7,
      "OPERATIONAL": 3,
      "POLICY": 12
    }
  },
  "pillar_scores": {
    "explainability": {
      "best_evidence_type": "POLICY",
      "display_name": "Explainability",
      "evidence_count": 1,
      "findings": "A proxy statement references external ethical guidelines. This document indicates a policy framework for AI development and use through the mention of ethical principles.",
      "max_score": 2,
      "path_to_improvement": "Publish user-facing explanation interfaces or documented appeal workflows.",
      "relevant_sources": [
        {
          "artifact_type": "proxy_statement",
          "source_id": "src_004",
          "source_tier": "third_party",
          "summary": "This proxy statement discusses the need for AI transparency and ethical guidelines, supporting the **transparency**, **governance**, and **oversight** pillars by highlighting the benefits of such reports and guidelines. It also touches upon AI risks like bias and data misuse, indirectly supporting the **fairness** and **privacy** pillars by acknowledging these concerns. While the board recommended against the proposal, the document references external ethical guidelines, indicating a policy framework for AI development and use, thus supporting the **explainability** pillar through the mention of ethical principles.",
          "title": "2024 Shareholder Proposal - AI Transparency and Board Oversight",
          "url": "https://collaborate.unpri.org/group/25566/home"
        }
      ],
      "score": 1,
      "source_count": 1
    },
    "external_accountability": {
      "best_evidence_type": "POLICY",
      "display_name": "Public Commitments & External Audits",
      "evidence_count": 4,
      "findings": "An SEC annual filing discusses material business risks associated with AI advancement and references specific regulations like the E.U. AI Act, which detail material requirements and sanctions. Additionally, a press release details the launch of the \"CBS Confirmed\" initiative and references an executive order establishing guardrails for AI, underscoring external accountability measures.",
      "max_score": 2,
      "path_to_improvement": "Publish third-party audit results, certifications, or regulatory compliance documentation.",
      "relevant_sources": [
        {
          "artifact_type": "sec_filing",
          "source_id": "src_002",
          "source_tier": "authority",
          "summary": "This SEC annual filing, the \"Form 10-K Annual Report (Fiscal Year 2024)\", provides evidence for **external_accountability** and **governance**. The report discusses material business risks associated with AI advancement, including cybersecurity and regulatory compliance challenges, and references specific regulations like the E.U. AI Act, which detail material requirements and sanctions. This indicates a need for robust governance frameworks and highlights potential external accountability mechanisms for AI technologies.",
          "title": "Form 10-K Annual Report (Fiscal Year 2024)",
          "url": "https://sec.gov/Archives/edgar/data/813828/000081382825000005/para-20241231.htm"
        },
        {
          "artifact_type": "press_release",
          "source_id": "src_005",
          "source_tier": "third_party",
          "summary": "This press release from CBS News details the launch of their \"CBS Confirmed\" initiative, which demonstrates evidence for **external accountability** and **governance**. The initiative's focus on recruiting forensic journalists and deploying advanced technology for deepfake detection, alongside training for Standards & Practices, highlights a commitment to responsible AI practices and operational oversight. Furthermore, the press release references an executive order establishing guardrails for AI, underscoring external accountability measures.",
          "title": "CBS News AI Deepfake Detection Initiative (CBS Confirmed)",
          "url": "https://deadline.com/2023/11/cbs-news-ai-deepfakes-misinformation-1235594684"
        }
      ],
      "score": 1,
      "source_count": 2
    },
    "fairness": {
      "best_evidence_type": "POLICY",
      "display_name": "Fairness & Bias Mitigation",
      "evidence_count": 2,
      "findings": "A proxy statement touches upon AI risks such as bias. This document acknowledges concerns related to AI bias.",
      "max_score": 2,
      "path_to_improvement": "Publish bias testing results, outcome monitoring, or vendor fairness certifications.",
      "relevant_sources": [
        {
          "artifact_type": "proxy_statement",
          "source_id": "src_004",
          "source_tier": "third_party",
          "summary": "This proxy statement discusses the need for AI transparency and ethical guidelines, supporting the **transparency**, **governance**, and **oversight** pillars by highlighting the benefits of such reports and guidelines. It also touches upon AI risks like bias and data misuse, indirectly supporting the **fairness** and **privacy** pillars by acknowledging these concerns. While the board recommended against the proposal, the document references external ethical guidelines, indicating a policy framework for AI development and use, thus supporting the **explainability** pillar through the mention of ethical principles.",
          "title": "2024 Shareholder Proposal - AI Transparency and Board Oversight",
          "url": "https://collaborate.unpri.org/group/25566/home"
        }
      ],
      "score": 1,
      "source_count": 1
    },
    "governance": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Governance & Accountability",
      "evidence_count": 17,
      "findings": "Paramount established a cross-company AI task force in 2023, outlining formal protocols and a policy framework for responsible AI use, risk management, and accountability. The company discusses material business risks and regulatory compliance challenges associated with AI advancement in an SEC annual filing, and a proxy statement highlights the benefits of AI ethical guidelines and references external ethical guidelines. Additionally, the \"CBS Confirmed\" initiative highlights a commitment to responsible AI practices and operational oversight, while a case study suggests governance over AI implementation through the integration of AI/ML and bespoke models.",
      "max_score": 2,
      "path_to_improvement": null,
      "relevant_sources": [
        {
          "artifact_type": "other",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This ESG report details Paramount's establishment of a cross-company AI task force in 2023, which supports the **governance** pillar by outlining formal protocols and a policy framework for responsible AI use, risk management, and accountability. The report also provides evidence for the **privacy** pillar by stating that these protocols ensure AI use aligns with company policies, including those related to privacy.",
          "title": "2023-2024 ESG Report - AI Task Force and Responsible AI Governance",
          "url": "https://paramount.com/sites/g/files/dxjhpe356/files/2024-10/Paramount_ESG_Report_2023-2024.pdf"
        },
        {
          "artifact_type": "sec_filing",
          "source_id": "src_002",
          "source_tier": "authority",
          "summary": "This SEC annual filing, the \"Form 10-K Annual Report (Fiscal Year 2024)\", provides evidence for **external_accountability** and **governance**. The report discusses material business risks associated with AI advancement, including cybersecurity and regulatory compliance challenges, and references specific regulations like the E.U. AI Act, which detail material requirements and sanctions. This indicates a need for robust governance frameworks and highlights potential external accountability mechanisms for AI technologies.",
          "title": "Form 10-K Annual Report (Fiscal Year 2024)",
          "url": "https://sec.gov/Archives/edgar/data/813828/000081382825000005/para-20241231.htm"
        },
        {
          "artifact_type": "proxy_statement",
          "source_id": "src_004",
          "source_tier": "third_party",
          "summary": "This proxy statement discusses the need for AI transparency and ethical guidelines, supporting the **transparency**, **governance**, and **oversight** pillars by highlighting the benefits of such reports and guidelines. It also touches upon AI risks like bias and data misuse, indirectly supporting the **fairness** and **privacy** pillars by acknowledging these concerns. While the board recommended against the proposal, the document references external ethical guidelines, indicating a policy framework for AI development and use, thus supporting the **explainability** pillar through the mention of ethical principles.",
          "title": "2024 Shareholder Proposal - AI Transparency and Board Oversight",
          "url": "https://collaborate.unpri.org/group/25566/home"
        },
        {
          "artifact_type": "press_release",
          "source_id": "src_005",
          "source_tier": "third_party",
          "summary": "This press release from CBS News details the launch of their \"CBS Confirmed\" initiative, which demonstrates evidence for **external accountability** and **governance**. The initiative's focus on recruiting forensic journalists and deploying advanced technology for deepfake detection, alongside training for Standards & Practices, highlights a commitment to responsible AI practices and operational oversight. Furthermore, the press release references an executive order establishing guardrails for AI, underscoring external accountability measures.",
          "title": "CBS News AI Deepfake Detection Initiative (CBS Confirmed)",
          "url": "https://deadline.com/2023/11/cbs-news-ai-deepfakes-misinformation-1235594684"
        },
        {
          "artifact_type": "other",
          "source_id": "src_006",
          "source_tier": "third_party",
          "summary": "This case study, \"Paramount+ AI/ML Integration - Recommendation Systems and Content Analysis,\" provides evidence for the **governance** and **transparency** pillars of responsible AI. The document highlights the integration of AI/ML and the use of bespoke models for specific functions, suggesting governance over AI implementation. Furthermore, mentions of AI-driven matching and an AI-powered platform imply transparency in how recommendations are generated and the capabilities of the AI tools used.",
          "title": "Paramount+ AI/ML Integration - Recommendation Systems and Content Analysis",
          "url": "https://andela.com/customer-stories/transforming-streaming-services-paramount-globals-ai-powered-innovation"
        },
        {
          "artifact_type": "sec_filing",
          "source_id": "src_008",
          "source_tier": "authority",
          "summary": "This Form 10-K annual report provides evidence for the **governance** pillar of responsible AI. The filing mentions AI as an important technology, indicating that the company is considering strategic implications and potential governance frameworks related to competitive access to AI.",
          "title": "Form 10-K Annual Report (Fiscal Year 2022)",
          "url": "https://sec.gov/Archives/edgar/data/813828/000081382823000005/para-20221231.htm"
        }
      ],
      "score": 2,
      "source_count": 6
    },
    "oversight": {
      "best_evidence_type": "POLICY",
      "display_name": "Human Oversight & Accountability",
      "evidence_count": 1,
      "findings": "A proxy statement discusses the need for AI ethical guidelines. This document highlights the benefits of such guidelines.",
      "max_score": 2,
      "path_to_improvement": "Publish override mechanisms, escalation processes, or appeal workflows.",
      "relevant_sources": [
        {
          "artifact_type": "proxy_statement",
          "source_id": "src_004",
          "source_tier": "third_party",
          "summary": "This proxy statement discusses the need for AI transparency and ethical guidelines, supporting the **transparency**, **governance**, and **oversight** pillars by highlighting the benefits of such reports and guidelines. It also touches upon AI risks like bias and data misuse, indirectly supporting the **fairness** and **privacy** pillars by acknowledging these concerns. While the board recommended against the proposal, the document references external ethical guidelines, indicating a policy framework for AI development and use, thus supporting the **explainability** pillar through the mention of ethical principles.",
          "title": "2024 Shareholder Proposal - AI Transparency and Board Oversight",
          "url": "https://collaborate.unpri.org/group/25566/home"
        }
      ],
      "score": 1,
      "source_count": 1
    },
    "privacy": {
      "best_evidence_type": "POLICY",
      "display_name": "Privacy & Security",
      "evidence_count": 3,
      "findings": "An ESG report states that protocols ensure AI use aligns with company policies, including those related to privacy. Additionally, a proxy statement touches upon AI risks like data misuse and acknowledges related concerns.",
      "max_score": 2,
      "path_to_improvement": "Publish AI-specific privacy impact assessments or data handling procedures.",
      "relevant_sources": [
        {
          "artifact_type": "other",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This ESG report details Paramount's establishment of a cross-company AI task force in 2023, which supports the **governance** pillar by outlining formal protocols and a policy framework for responsible AI use, risk management, and accountability. The report also provides evidence for the **privacy** pillar by stating that these protocols ensure AI use aligns with company policies, including those related to privacy.",
          "title": "2023-2024 ESG Report - AI Task Force and Responsible AI Governance",
          "url": "https://paramount.com/sites/g/files/dxjhpe356/files/2024-10/Paramount_ESG_Report_2023-2024.pdf"
        },
        {
          "artifact_type": "proxy_statement",
          "source_id": "src_004",
          "source_tier": "third_party",
          "summary": "This proxy statement discusses the need for AI transparency and ethical guidelines, supporting the **transparency**, **governance**, and **oversight** pillars by highlighting the benefits of such reports and guidelines. It also touches upon AI risks like bias and data misuse, indirectly supporting the **fairness** and **privacy** pillars by acknowledging these concerns. While the board recommended against the proposal, the document references external ethical guidelines, indicating a policy framework for AI development and use, thus supporting the **explainability** pillar through the mention of ethical principles.",
          "title": "2024 Shareholder Proposal - AI Transparency and Board Oversight",
          "url": "https://collaborate.unpri.org/group/25566/home"
        }
      ],
      "score": 1,
      "source_count": 2
    },
    "transparency": {
      "best_evidence_type": "POLICY",
      "display_name": "Transparency",
      "evidence_count": 7,
      "findings": "A proxy statement discusses the need for AI transparency and highlights the benefits of related reports and guidelines. Additionally, a case study mentions AI-driven matching and an AI-powered platform, which suggests transparency in how recommendations are generated and regarding the capabilities of the AI tools used.",
      "max_score": 2,
      "path_to_improvement": "Publish detailed documentation (model cards, system specs) for AI systems deployed.",
      "relevant_sources": [
        {
          "artifact_type": "proxy_statement",
          "source_id": "src_004",
          "source_tier": "third_party",
          "summary": "This proxy statement discusses the need for AI transparency and ethical guidelines, supporting the **transparency**, **governance**, and **oversight** pillars by highlighting the benefits of such reports and guidelines. It also touches upon AI risks like bias and data misuse, indirectly supporting the **fairness** and **privacy** pillars by acknowledging these concerns. While the board recommended against the proposal, the document references external ethical guidelines, indicating a policy framework for AI development and use, thus supporting the **explainability** pillar through the mention of ethical principles.",
          "title": "2024 Shareholder Proposal - AI Transparency and Board Oversight",
          "url": "https://collaborate.unpri.org/group/25566/home"
        },
        {
          "artifact_type": "other",
          "source_id": "src_006",
          "source_tier": "third_party",
          "summary": "This case study, \"Paramount+ AI/ML Integration - Recommendation Systems and Content Analysis,\" provides evidence for the **governance** and **transparency** pillars of responsible AI. The document highlights the integration of AI/ML and the use of bespoke models for specific functions, suggesting governance over AI implementation. Furthermore, mentions of AI-driven matching and an AI-powered platform imply transparency in how recommendations are generated and the capabilities of the AI tools used.",
          "title": "Paramount+ AI/ML Integration - Recommendation Systems and Content Analysis",
          "url": "https://andela.com/customer-stories/transforming-streaming-services-paramount-globals-ai-powered-innovation"
        }
      ],
      "score": 1,
      "source_count": 2
    }
  },
  "published_at": "2026-02-23T21:56:54Z",
  "run_id": "20260203_000255_bea6",
  "schema_version": "1.0",
  "summary": {
    "key_gaps": [],
    "key_strengths": [
      "Governance & Accountability"
    ],
    "overall_findings": "Paramount's public disclosures detail operational practices for governance, including the establishment of a cross-company AI task force in 2023 and formal protocols for responsible AI use. All 7 evaluated pillars have documented public evidence, drawing from 8 publicly available sources. Policy-level evidence is present across the remaining pillars, with transparency disclosures discussing the need for AI transparency and fairness materials acknowledging concerns related to AI bias. Further policy documentation includes references to external ethical guidelines for explainability and discussions on the need for AI ethical guidelines for oversight. Additionally, privacy protocols ensure AI use aligns with company policies, and external accountability is addressed through SEC annual filings referencing specific regulations like the E.U. AI Act.",
    "pillars_operational": 1,
    "pillars_policy_only": 6,
    "pillars_with_evidence": 7,
    "pillars_without_evidence": 0,
    "total_evidence_items": 22,
    "total_sources_used": 6
  }
}
