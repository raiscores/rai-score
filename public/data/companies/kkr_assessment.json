{
  "aggregate": {
    "max_possible_score": 14,
    "percent_score": 14.3,
    "star_display": "â˜…",
    "star_rating": 1,
    "total_score": 2
  },
  "company": "KKR",
  "company_slug": "kkr",
  "evidence_breakdown": {
    "by_type": {
      "NARRATIVE": 1,
      "OPERATIONAL": 0,
      "POLICY": 7
    }
  },
  "pillar_scores": {
    "explainability": {
      "best_evidence_type": null,
      "display_name": "Explainability",
      "evidence_count": 0,
      "findings": null,
      "max_score": 2,
      "path_to_improvement": "Document how explanations are provided to users affected by AI decisions.",
      "relevant_sources": [],
      "score": 0,
      "source_count": 0
    },
    "external_accountability": {
      "best_evidence_type": null,
      "display_name": "Public Commitments & External Audits",
      "evidence_count": 0,
      "findings": null,
      "max_score": 2,
      "path_to_improvement": "Obtain external validation of AI practices or require vendor certifications.",
      "relevant_sources": [],
      "score": 0,
      "source_count": 0
    },
    "fairness": {
      "best_evidence_type": null,
      "display_name": "Fairness & Bias Mitigation",
      "evidence_count": 0,
      "findings": null,
      "max_score": 2,
      "path_to_improvement": "Document bias testing procedures or vendor AI fairness requirements.",
      "relevant_sources": [],
      "score": 0,
      "source_count": 0
    },
    "governance": {
      "best_evidence_type": "POLICY",
      "display_name": "Governance & Accountability",
      "evidence_count": 8,
      "findings": "Reports describe the establishment of a generative AI working group for direct governance of AI strategy and program, referencing the implementation of controls and training, and outlining a due diligence process for assessing AI materiality in investment decisions. Published materials also describe the firm's perspective on risks associated with irresponsible data handling in AI deployment, state the importance of responsible data practices, and outline policies for evaluating AI's impact on business models and assessing AI risks for investments.",
      "max_score": 2,
      "path_to_improvement": "Name an AI governance body with defined mandate covering all AI use.",
      "relevant_sources": [
        {
          "artifact_type": "other",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "KKR's 2023 Sustainability Report demonstrates a commitment to responsible AI by establishing a generative AI working group for direct governance of their AI strategy and program. This report provides evidence for the **governance** pillar through the creation of this working group, the implementation of controls and training, and a due diligence process for assessing AI materiality in investment decisions. It also supports the **oversight** pillar by detailing the working group's role in managing AI-related risks and mentioning cybersecurity initiatives like Project Shield.",
          "title": "KKR 2023 Sustainability Report - Generative AI Governance",
          "url": "https://kkr.com/content/dam/kkr/sustainability/pdf/2023-sustainability-report.pdf"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_003",
          "source_tier": "company_owned",
          "summary": "This KKR Insights blog post provides evidence for the **governance** and **privacy** pillars of responsible AI. The article highlights the firm's perspective on the reputational and regulatory risks associated with irresponsible data handling, directly linking these concerns to the deployment of AI and machine learning technologies. This narrative emphasizes the importance of responsible data practices within the context of AI development and deployment.",
          "title": "KKR Insights: Data Responsibility and Sustainability",
          "url": "https://kkr.com/insights/how-can-handling-data-responsibly-make-companies-more-sustainable"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_004",
          "source_tier": "company_owned",
          "summary": "This KKR Insights blog post provides evidence for the **governance** pillar of responsible AI. It highlights a required analysis for investments, demonstrating a policy for evaluating AI's impact on business models, and discusses awareness of AI risks and conscious investment decisions, indicating a policy of risk assessment for investments.",
          "title": "KKR Insights: DeepSeek and the Evolution of Large Language Models",
          "url": "https://kkr.com/insights/deepseek-large-language-models"
        }
      ],
      "score": 1,
      "source_count": 3
    },
    "oversight": {
      "best_evidence_type": "POLICY",
      "display_name": "Human Oversight & Accountability",
      "evidence_count": 1,
      "findings": "Reports describe the role of a generative AI working group in managing AI-related risks. Cybersecurity initiatives are also referenced in relation to oversight practices.",
      "max_score": 2,
      "path_to_improvement": "Publish override mechanisms, escalation processes, or appeal workflows.",
      "relevant_sources": [
        {
          "artifact_type": "other",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "KKR's 2023 Sustainability Report demonstrates a commitment to responsible AI by establishing a generative AI working group for direct governance of their AI strategy and program. This report provides evidence for the **governance** pillar through the creation of this working group, the implementation of controls and training, and a due diligence process for assessing AI materiality in investment decisions. It also supports the **oversight** pillar by detailing the working group's role in managing AI-related risks and mentioning cybersecurity initiatives like Project Shield.",
          "title": "KKR 2023 Sustainability Report - Generative AI Governance",
          "url": "https://kkr.com/content/dam/kkr/sustainability/pdf/2023-sustainability-report.pdf"
        }
      ],
      "score": 1,
      "source_count": 1
    },
    "privacy": {
      "best_evidence_type": "NARRATIVE",
      "display_name": "Privacy & Security",
      "evidence_count": 1,
      "findings": "Published materials describe the firm's perspective on reputational and regulatory risks associated with irresponsible data handling, linking these concerns to the deployment of AI and machine learning technologies. These materials also state the importance of responsible data practices within the context of AI development and deployment.",
      "max_score": 2,
      "path_to_improvement": "Document data protection practices for AI systems, including vendor AI data handling.",
      "relevant_sources": [
        {
          "artifact_type": "blog_post",
          "source_id": "src_003",
          "source_tier": "company_owned",
          "summary": "This KKR Insights blog post provides evidence for the **governance** and **privacy** pillars of responsible AI. The article highlights the firm's perspective on the reputational and regulatory risks associated with irresponsible data handling, directly linking these concerns to the deployment of AI and machine learning technologies. This narrative emphasizes the importance of responsible data practices within the context of AI development and deployment.",
          "title": "KKR Insights: Data Responsibility and Sustainability",
          "url": "https://kkr.com/insights/how-can-handling-data-responsibly-make-companies-more-sustainable"
        }
      ],
      "score": 0,
      "source_count": 1
    },
    "transparency": {
      "best_evidence_type": null,
      "display_name": "Transparency",
      "evidence_count": 0,
      "findings": null,
      "max_score": 2,
      "path_to_improvement": "Document AI systems in use, including vendor/third-party AI tools.",
      "relevant_sources": [],
      "score": 0,
      "source_count": 0
    }
  },
  "published_at": "2026-02-23T21:53:23Z",
  "run_id": "20260202_234844_5f72",
  "schema_version": "1.0",
  "summary": {
    "key_gaps": [
      "Transparency",
      "Fairness & Bias Mitigation",
      "Explainability",
      "Privacy & Security",
      "Public Commitments & External Audits"
    ],
    "key_strengths": [],
    "overall_findings": "Based on 5 publicly available sources, KKR's published materials address 2 of 7 evaluated responsible AI pillars: oversight and governance. For oversight, disclosures describe a generative AI working group's role in managing AI-related risks and reference cybersecurity initiatives like Project Shield. Regarding governance, materials describe the establishment of a generative AI working group for direct governance of AI strategy and program, alongside references to controls and training related to AI. No qualifying public evidence was found for the majority of the 7 evaluated pillars.",
    "pillars_operational": 0,
    "pillars_policy_only": 2,
    "pillars_with_evidence": 2,
    "pillars_without_evidence": 5,
    "total_evidence_items": 8,
    "total_sources_used": 3
  }
}
