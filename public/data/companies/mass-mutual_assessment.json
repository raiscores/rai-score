{
  "aggregate": {
    "max_possible_score": 14,
    "percent_score": 71.4,
    "star_display": "★★★★",
    "star_rating": 4,
    "total_score": 10
  },
  "company": "Mass Mutual",
  "company_slug": "mass-mutual",
  "evidence_breakdown": {
    "by_type": {
      "NARRATIVE": 16,
      "OPERATIONAL": 9,
      "POLICY": 6
    }
  },
  "pillar_scores": {
    "explainability": {
      "best_evidence_type": null,
      "display_name": "Explainability",
      "evidence_count": 0,
      "findings": null,
      "max_score": 2,
      "path_to_improvement": "Document how explanations are provided to users affected by AI decisions.",
      "relevant_sources": [],
      "score": 0,
      "source_count": 0
    },
    "external_accountability": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Public Commitments & External Audits",
      "evidence_count": 6,
      "findings": "MassMutual describes assigned roles and responsibilities for the AI system lifecycle, including model reviews and satisfying regulatory requirements. The company also mentions assigned roles and responsibilities for AI systems, governance processes, and model reviews. References to regulators and laws are referenced, alongside the mention of reviewing algorithms for fairness and compliance.",
      "max_score": 2,
      "path_to_improvement": null,
      "relevant_sources": [
        {
          "artifact_type": "help_page",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This company-owned help page, \"AI Systems - Responsible Use Principles,\" provides evidence for **governance**, **transparency**, **fairness**, and **external accountability**. It outlines guiding principles for AI systems, implying transparency through documented principles and explicitly stating fairness as a core tenet. The document also supports governance by mentioning alignment with laws and regulations, and external accountability through the discussion of assigned roles and responsibilities for the AI system lifecycle, including model reviews and satisfying regulatory requirements.",
          "title": "AI Systems - Responsible Use Principles",
          "url": "https://massmutual.com/protecting-your-information/ai-systems"
        },
        {
          "artifact_type": "press_release",
          "source_id": "src_003",
          "source_tier": "company_owned",
          "summary": "This press release, \"2024 Sustainability Report - AI Investments for Financial Access,\" provides evidence for **governance, oversight, transparency, and external accountability**. It details investments in AI-driven companies like Ocho and GreenLyne.AI, which serve underserved communities. The report mentions assigned roles and responsibilities for AI systems, governance processes, model reviews, and the use of human underwriters, all of which support these responsible AI pillars.",
          "title": "2024 Sustainability Report - AI Investments for Financial Access",
          "url": "https://massmutual.com/global/media/shared/doc/sustainability/2024sustainabilityreport.pdf"
        },
        {
          "artifact_type": "help_page",
          "source_id": "src_008",
          "source_tier": "third_party",
          "summary": "The Boston University Roundtable on Algorithmic Fairness, a help page, provides evidence for **external_accountability**, **fairness**, **governance**, and **privacy**. It supports **fairness** by mentioning algorithms and discriminatory practices, as well as AI systems and social justice. **External_accountability** is indicated through references to regulators and laws. The source also supports **governance** by discussing AI governance functions and driving change, and **privacy** by specifically mentioning privacy for AI.",
          "title": "Boston University Roundtable on Algorithmic Fairness - October 2023",
          "url": "https://bu.edu/pitun2023/program/roundtable-on-algorithmic-fairness"
        },
        {
          "artifact_type": "other",
          "source_id": "src_009",
          "source_tier": "third_party",
          "summary": "This third-party document, \"Boston University CDS - Algorithmic Fairness Requires Diverse Developers,\" provides evidence for **external_accountability, fairness, governance, and oversight**. It highlights MassMutual's multidisciplinary approach and data/AI governance policies, mentioning the review of algorithms for fairness and compliance, which supports **fairness** and **external_accountability**. The document also touches upon AI governance roles and policies, indicating support for **governance**, and the ability to contest algorithmic decisions, which relates to **oversight**.",
          "title": "Boston University CDS - Algorithmic Fairness Requires Diverse Developers",
          "url": "https://bu.edu/cds-faculty/2023/11/02/algorithmic-fairness-requires-diverse-developers-regulatory-vigilance"
        }
      ],
      "score": 2,
      "source_count": 4
    },
    "fairness": {
      "best_evidence_type": "POLICY",
      "display_name": "Fairness & Bias Mitigation",
      "evidence_count": 8,
      "findings": "MassMutual explicitly states fairness as a core tenet for AI systems and references an effort towards fairness through its M3S system being carefully calibrated to mirror risk distribution. The company mentions algorithms, discriminatory practices, and AI systems in the context of social justice. Additionally, the review of algorithms for fairness is mentioned.",
      "max_score": 2,
      "path_to_improvement": "Publish bias testing results, outcome monitoring, or vendor fairness certifications.",
      "relevant_sources": [
        {
          "artifact_type": "help_page",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This company-owned help page, \"AI Systems - Responsible Use Principles,\" provides evidence for **governance**, **transparency**, **fairness**, and **external accountability**. It outlines guiding principles for AI systems, implying transparency through documented principles and explicitly stating fairness as a core tenet. The document also supports governance by mentioning alignment with laws and regulations, and external accountability through the discussion of assigned roles and responsibilities for the AI system lifecycle, including model reviews and satisfying regulatory requirements.",
          "title": "AI Systems - Responsible Use Principles",
          "url": "https://massmutual.com/protecting-your-information/ai-systems"
        },
        {
          "artifact_type": "technical_paper",
          "source_id": "src_005",
          "source_tier": "third_party",
          "summary": "This technical paper, \"Life Underwriting Requirements Guide - MassMutual Mortality Score,\" provides evidence for **transparency** by detailing the inputs and functions of MassMutual's proprietary algorithmic underwriting model (M3S), which replaces a traditional system and operates as a fully automated decision-making system. The paper also offers evidence for **fairness** by suggesting an effort towards fairness through the M3S system being \"carefully calibrated to mirror the same risk distribution.\"",
          "title": "Life Underwriting Requirements Guide - MassMutual Mortality Score",
          "url": "https://buiusa.com/wp-content/uploads/2024/11/MassMutual-Underwriting-Guideline-2020.pdf"
        },
        {
          "artifact_type": "help_page",
          "source_id": "src_008",
          "source_tier": "third_party",
          "summary": "The Boston University Roundtable on Algorithmic Fairness, a help page, provides evidence for **external_accountability**, **fairness**, **governance**, and **privacy**. It supports **fairness** by mentioning algorithms and discriminatory practices, as well as AI systems and social justice. **External_accountability** is indicated through references to regulators and laws. The source also supports **governance** by discussing AI governance functions and driving change, and **privacy** by specifically mentioning privacy for AI.",
          "title": "Boston University Roundtable on Algorithmic Fairness - October 2023",
          "url": "https://bu.edu/pitun2023/program/roundtable-on-algorithmic-fairness"
        },
        {
          "artifact_type": "other",
          "source_id": "src_009",
          "source_tier": "third_party",
          "summary": "This third-party document, \"Boston University CDS - Algorithmic Fairness Requires Diverse Developers,\" provides evidence for **external_accountability, fairness, governance, and oversight**. It highlights MassMutual's multidisciplinary approach and data/AI governance policies, mentioning the review of algorithms for fairness and compliance, which supports **fairness** and **external_accountability**. The document also touches upon AI governance roles and policies, indicating support for **governance**, and the ability to contest algorithmic decisions, which relates to **oversight**.",
          "title": "Boston University CDS - Algorithmic Fairness Requires Diverse Developers",
          "url": "https://bu.edu/cds-faculty/2023/11/02/algorithmic-fairness-requires-diverse-developers-regulatory-vigilance"
        }
      ],
      "score": 1,
      "source_count": 4
    },
    "governance": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Governance & Accountability",
      "evidence_count": 16,
      "findings": "MassMutual outlines guiding principles for AI systems, mentioning alignment with laws and regulations, and describes assigned roles and responsibilities for the AI system lifecycle, including model reviews and satisfying regulatory requirements. The company describes voluntarily created data governance principles and AI acquisition and vendor selection practices. Furthermore, MassMutual describes its multidisciplinary approach and data/AI governance policies, mentioning the review of algorithms for fairness and compliance.",
      "max_score": 2,
      "path_to_improvement": null,
      "relevant_sources": [
        {
          "artifact_type": "help_page",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This company-owned help page, \"AI Systems - Responsible Use Principles,\" provides evidence for **governance**, **transparency**, **fairness**, and **external accountability**. It outlines guiding principles for AI systems, implying transparency through documented principles and explicitly stating fairness as a core tenet. The document also supports governance by mentioning alignment with laws and regulations, and external accountability through the discussion of assigned roles and responsibilities for the AI system lifecycle, including model reviews and satisfying regulatory requirements.",
          "title": "AI Systems - Responsible Use Principles",
          "url": "https://massmutual.com/protecting-your-information/ai-systems"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_002",
          "source_tier": "third_party",
          "summary": "This blog post provides evidence for the **governance**, **oversight**, **privacy**, and **transparency** pillars of responsible AI. It supports governance and privacy by detailing voluntarily created data governance principles that emphasize data transparency and privacy preservation. The post also supports oversight and transparency by highlighting the importance of human review for AI-initiated decisions and the continuous monitoring of automated decision-making systems.",
          "title": "Enhancing the Way We Do Business with AI - Governance Framework",
          "url": "https://corporatereport.com/massmutual/2024/ar/products-and-services/enhancing-business-with-ai.php"
        },
        {
          "artifact_type": "press_release",
          "source_id": "src_003",
          "source_tier": "company_owned",
          "summary": "This press release, \"2024 Sustainability Report - AI Investments for Financial Access,\" provides evidence for **governance, oversight, transparency, and external accountability**. It details investments in AI-driven companies like Ocho and GreenLyne.AI, which serve underserved communities. The report mentions assigned roles and responsibilities for AI systems, governance processes, model reviews, and the use of human underwriters, all of which support these responsible AI pillars.",
          "title": "2024 Sustainability Report - AI Investments for Financial Access",
          "url": "https://massmutual.com/global/media/shared/doc/sustainability/2024sustainabilityreport.pdf"
        },
        {
          "artifact_type": "press_release",
          "source_id": "src_007",
          "source_tier": "third_party",
          "summary": "This press release provides evidence for **governance**, **oversight**, and **transparency**. It details MassMutual's cautious AI strategy, including internal-only generative AI use and the development of virtual assistants with human oversight, supporting the **oversight** pillar. The release also describes the company's data infrastructure modernization for AI and the use of specific AI models, aligning with the **transparency** pillar by explaining how data is leveraged. Furthermore, the discussion of AI acquisition and vendor selection practices supports the **governance** pillar.",
          "title": "MassMutual CIO Interview on AI Strategy and Data Infrastructure",
          "url": "https://fortune.com/2025/02/26/massmutual-cio-data-ai"
        },
        {
          "artifact_type": "help_page",
          "source_id": "src_008",
          "source_tier": "third_party",
          "summary": "The Boston University Roundtable on Algorithmic Fairness, a help page, provides evidence for **external_accountability**, **fairness**, **governance**, and **privacy**. It supports **fairness** by mentioning algorithms and discriminatory practices, as well as AI systems and social justice. **External_accountability** is indicated through references to regulators and laws. The source also supports **governance** by discussing AI governance functions and driving change, and **privacy** by specifically mentioning privacy for AI.",
          "title": "Boston University Roundtable on Algorithmic Fairness - October 2023",
          "url": "https://bu.edu/pitun2023/program/roundtable-on-algorithmic-fairness"
        },
        {
          "artifact_type": "other",
          "source_id": "src_009",
          "source_tier": "third_party",
          "summary": "This third-party document, \"Boston University CDS - Algorithmic Fairness Requires Diverse Developers,\" provides evidence for **external_accountability, fairness, governance, and oversight**. It highlights MassMutual's multidisciplinary approach and data/AI governance policies, mentioning the review of algorithms for fairness and compliance, which supports **fairness** and **external_accountability**. The document also touches upon AI governance roles and policies, indicating support for **governance**, and the ability to contest algorithmic decisions, which relates to **oversight**.",
          "title": "Boston University CDS - Algorithmic Fairness Requires Diverse Developers",
          "url": "https://bu.edu/cds-faculty/2023/11/02/algorithmic-fairness-requires-diverse-developers-regulatory-vigilance"
        }
      ],
      "score": 2,
      "source_count": 6
    },
    "oversight": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Human Oversight & Accountability",
      "evidence_count": 5,
      "findings": "MassMutual references the importance of human review for AI-initiated decisions and continuous monitoring of automated decision-making systems. The company mentions assigned roles and responsibilities for AI systems, governance processes, model reviews, and the use of human underwriters. MassMutual also describes its cautious AI strategy, including internal-only generative AI use and the development of virtual assistants with human oversight, and references the ability to contest algorithmic decisions.",
      "max_score": 2,
      "path_to_improvement": null,
      "relevant_sources": [
        {
          "artifact_type": "blog_post",
          "source_id": "src_002",
          "source_tier": "third_party",
          "summary": "This blog post provides evidence for the **governance**, **oversight**, **privacy**, and **transparency** pillars of responsible AI. It supports governance and privacy by detailing voluntarily created data governance principles that emphasize data transparency and privacy preservation. The post also supports oversight and transparency by highlighting the importance of human review for AI-initiated decisions and the continuous monitoring of automated decision-making systems.",
          "title": "Enhancing the Way We Do Business with AI - Governance Framework",
          "url": "https://corporatereport.com/massmutual/2024/ar/products-and-services/enhancing-business-with-ai.php"
        },
        {
          "artifact_type": "press_release",
          "source_id": "src_003",
          "source_tier": "company_owned",
          "summary": "This press release, \"2024 Sustainability Report - AI Investments for Financial Access,\" provides evidence for **governance, oversight, transparency, and external accountability**. It details investments in AI-driven companies like Ocho and GreenLyne.AI, which serve underserved communities. The report mentions assigned roles and responsibilities for AI systems, governance processes, model reviews, and the use of human underwriters, all of which support these responsible AI pillars.",
          "title": "2024 Sustainability Report - AI Investments for Financial Access",
          "url": "https://massmutual.com/global/media/shared/doc/sustainability/2024sustainabilityreport.pdf"
        },
        {
          "artifact_type": "press_release",
          "source_id": "src_007",
          "source_tier": "third_party",
          "summary": "This press release provides evidence for **governance**, **oversight**, and **transparency**. It details MassMutual's cautious AI strategy, including internal-only generative AI use and the development of virtual assistants with human oversight, supporting the **oversight** pillar. The release also describes the company's data infrastructure modernization for AI and the use of specific AI models, aligning with the **transparency** pillar by explaining how data is leveraged. Furthermore, the discussion of AI acquisition and vendor selection practices supports the **governance** pillar.",
          "title": "MassMutual CIO Interview on AI Strategy and Data Infrastructure",
          "url": "https://fortune.com/2025/02/26/massmutual-cio-data-ai"
        },
        {
          "artifact_type": "other",
          "source_id": "src_009",
          "source_tier": "third_party",
          "summary": "This third-party document, \"Boston University CDS - Algorithmic Fairness Requires Diverse Developers,\" provides evidence for **external_accountability, fairness, governance, and oversight**. It highlights MassMutual's multidisciplinary approach and data/AI governance policies, mentioning the review of algorithms for fairness and compliance, which supports **fairness** and **external_accountability**. The document also touches upon AI governance roles and policies, indicating support for **governance**, and the ability to contest algorithmic decisions, which relates to **oversight**.",
          "title": "Boston University CDS - Algorithmic Fairness Requires Diverse Developers",
          "url": "https://bu.edu/cds-faculty/2023/11/02/algorithmic-fairness-requires-diverse-developers-regulatory-vigilance"
        }
      ],
      "score": 2,
      "source_count": 4
    },
    "privacy": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Privacy & Security",
      "evidence_count": 3,
      "findings": "MassMutual's voluntarily created data governance principles state privacy preservation. Additionally, privacy for AI is specifically mentioned.",
      "max_score": 2,
      "path_to_improvement": "Publish AI-specific privacy impact assessments or data handling procedures.",
      "relevant_sources": [
        {
          "artifact_type": "blog_post",
          "source_id": "src_002",
          "source_tier": "third_party",
          "summary": "This blog post provides evidence for the **governance**, **oversight**, **privacy**, and **transparency** pillars of responsible AI. It supports governance and privacy by detailing voluntarily created data governance principles that emphasize data transparency and privacy preservation. The post also supports oversight and transparency by highlighting the importance of human review for AI-initiated decisions and the continuous monitoring of automated decision-making systems.",
          "title": "Enhancing the Way We Do Business with AI - Governance Framework",
          "url": "https://corporatereport.com/massmutual/2024/ar/products-and-services/enhancing-business-with-ai.php"
        },
        {
          "artifact_type": "help_page",
          "source_id": "src_008",
          "source_tier": "third_party",
          "summary": "The Boston University Roundtable on Algorithmic Fairness, a help page, provides evidence for **external_accountability**, **fairness**, **governance**, and **privacy**. It supports **fairness** by mentioning algorithms and discriminatory practices, as well as AI systems and social justice. **External_accountability** is indicated through references to regulators and laws. The source also supports **governance** by discussing AI governance functions and driving change, and **privacy** by specifically mentioning privacy for AI.",
          "title": "Boston University Roundtable on Algorithmic Fairness - October 2023",
          "url": "https://bu.edu/pitun2023/program/roundtable-on-algorithmic-fairness"
        }
      ],
      "score": 1,
      "source_count": 2
    },
    "transparency": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Transparency",
      "evidence_count": 12,
      "findings": "MassMutual outlines guiding principles for AI systems and describes voluntarily created data governance principles that state data transparency. The company references the importance of human review for AI-initiated decisions, continuous monitoring of automated decision-making systems, and describes the inputs and functions of its proprietary algorithmic underwriting model (M3S). Additionally, MassMutual describes its data infrastructure modernization for AI, including how data is leveraged.",
      "max_score": 2,
      "path_to_improvement": null,
      "relevant_sources": [
        {
          "artifact_type": "help_page",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This company-owned help page, \"AI Systems - Responsible Use Principles,\" provides evidence for **governance**, **transparency**, **fairness**, and **external accountability**. It outlines guiding principles for AI systems, implying transparency through documented principles and explicitly stating fairness as a core tenet. The document also supports governance by mentioning alignment with laws and regulations, and external accountability through the discussion of assigned roles and responsibilities for the AI system lifecycle, including model reviews and satisfying regulatory requirements.",
          "title": "AI Systems - Responsible Use Principles",
          "url": "https://massmutual.com/protecting-your-information/ai-systems"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_002",
          "source_tier": "third_party",
          "summary": "This blog post provides evidence for the **governance**, **oversight**, **privacy**, and **transparency** pillars of responsible AI. It supports governance and privacy by detailing voluntarily created data governance principles that emphasize data transparency and privacy preservation. The post also supports oversight and transparency by highlighting the importance of human review for AI-initiated decisions and the continuous monitoring of automated decision-making systems.",
          "title": "Enhancing the Way We Do Business with AI - Governance Framework",
          "url": "https://corporatereport.com/massmutual/2024/ar/products-and-services/enhancing-business-with-ai.php"
        },
        {
          "artifact_type": "press_release",
          "source_id": "src_003",
          "source_tier": "company_owned",
          "summary": "This press release, \"2024 Sustainability Report - AI Investments for Financial Access,\" provides evidence for **governance, oversight, transparency, and external accountability**. It details investments in AI-driven companies like Ocho and GreenLyne.AI, which serve underserved communities. The report mentions assigned roles and responsibilities for AI systems, governance processes, model reviews, and the use of human underwriters, all of which support these responsible AI pillars.",
          "title": "2024 Sustainability Report - AI Investments for Financial Access",
          "url": "https://massmutual.com/global/media/shared/doc/sustainability/2024sustainabilityreport.pdf"
        },
        {
          "artifact_type": "technical_paper",
          "source_id": "src_005",
          "source_tier": "third_party",
          "summary": "This technical paper, \"Life Underwriting Requirements Guide - MassMutual Mortality Score,\" provides evidence for **transparency** by detailing the inputs and functions of MassMutual's proprietary algorithmic underwriting model (M3S), which replaces a traditional system and operates as a fully automated decision-making system. The paper also offers evidence for **fairness** by suggesting an effort towards fairness through the M3S system being \"carefully calibrated to mirror the same risk distribution.\"",
          "title": "Life Underwriting Requirements Guide - MassMutual Mortality Score",
          "url": "https://buiusa.com/wp-content/uploads/2024/11/MassMutual-Underwriting-Guideline-2020.pdf"
        },
        {
          "artifact_type": "press_release",
          "source_id": "src_007",
          "source_tier": "third_party",
          "summary": "This press release provides evidence for **governance**, **oversight**, and **transparency**. It details MassMutual's cautious AI strategy, including internal-only generative AI use and the development of virtual assistants with human oversight, supporting the **oversight** pillar. The release also describes the company's data infrastructure modernization for AI and the use of specific AI models, aligning with the **transparency** pillar by explaining how data is leveraged. Furthermore, the discussion of AI acquisition and vendor selection practices supports the **governance** pillar.",
          "title": "MassMutual CIO Interview on AI Strategy and Data Infrastructure",
          "url": "https://fortune.com/2025/02/26/massmutual-cio-data-ai"
        }
      ],
      "score": 2,
      "source_count": 5
    }
  },
  "published_at": "2026-02-23T21:54:48Z",
  "run_id": "20260218_022108_c5ea",
  "schema_version": "1.0",
  "summary": {
    "key_gaps": [
      "Explainability"
    ],
    "key_strengths": [
      "Transparency",
      "Human Oversight & Accountability",
      "Governance & Accountability",
      "Public Commitments & External Audits"
    ],
    "overall_findings": "Mass Mutual's public disclosures show evidence of both operational practices and policy-level commitments across its responsible AI framework. Operational practices include outlining guiding principles for AI systems, referencing the importance of human review for AI-initiated decisions, and describing assigned roles and responsibilities for the AI system lifecycle. Furthermore, fairness is explicitly stated as a core tenet for AI systems, and privacy preservation is noted in voluntarily created data governance principles, contributing to coverage across 6 of 7 evaluated pillars. No qualifying public evidence was found for explainability. These findings are based on a review of 12 publicly available sources.",
    "pillars_operational": 4,
    "pillars_policy_only": 2,
    "pillars_with_evidence": 6,
    "pillars_without_evidence": 1,
    "total_evidence_items": 31,
    "total_sources_used": 7
  }
}
