{
  "aggregate": {
    "max_possible_score": 14,
    "percent_score": 64.3,
    "star_display": "★★★",
    "star_rating": 3,
    "total_score": 9
  },
  "company": "Berkshire Hathaway",
  "company_slug": "berkshire-hathaway",
  "evidence_breakdown": {
    "by_type": {
      "NARRATIVE": 22,
      "OPERATIONAL": 18,
      "POLICY": 58
    }
  },
  "pillar_scores": {
    "explainability": {
      "best_evidence_type": "POLICY",
      "display_name": "Explainability",
      "evidence_count": 2,
      "findings": "Reports describe the AI's capability to explain malicious content.",
      "max_score": 2,
      "path_to_improvement": "Publish user-facing explanation interfaces or documented appeal workflows.",
      "relevant_sources": [
        {
          "artifact_type": "press_release",
          "source_id": "src_007",
          "source_tier": "third_party",
          "summary": "This press release provides evidence for **transparency** and **governance** by detailing the data sources and model inputs used by Zesty.ai's climate risk analytics platform, including aerial imagery, weather, and real estate data. It also supports **explainability** by describing how the Z-FIRE model derives property-level risk scores based on extensive training data and loss history. The announcement highlights the proprietary nature of the data and model building, implying data governance practices.",
          "title": "Berkshire Hathaway Homestate Companies Selects Zesty.ai for Climate Risk Analytics",
          "url": "https://iireporter.com/berkshire-hathaway-homestate-selects-zesty-ai-for-climate-risk-analysis"
        },
        {
          "artifact_type": "other",
          "source_id": "src_014",
          "source_tier": "third_party",
          "summary": "This third-party report on Marmon Holdings' deployment of Abnormal's AI-powered email security provides evidence for **explainability** and **transparency**. The report describes the AI's capability to learn and understand communications, including its ability to explain malicious content, which supports explainability. Furthermore, the mention of the AI's automated remediation functions supports transparency by detailing how the system operates.",
          "title": "Marmon Holdings Secures 120+ Networks with Abnormal Security AI",
          "url": "https://abnormal.ai/resources/marmon"
        }
      ],
      "score": 1,
      "source_count": 2
    },
    "external_accountability": {
      "best_evidence_type": "POLICY",
      "display_name": "Public Commitments & External Audits",
      "evidence_count": 2,
      "findings": "A shareholder proposal requested an independent AI committee for risk oversight. Additionally, sources advocate for increased transparency in AI use to enable shareholder evaluation of risks.",
      "max_score": 2,
      "path_to_improvement": "Publish third-party audit results, certifications, or regulatory compliance documentation.",
      "relevant_sources": [
        {
          "artifact_type": "proxy_statement",
          "source_id": "src_001",
          "source_tier": "authority",
          "summary": "This proxy statement provides evidence for **governance**, **oversight**, **external_accountability**, **fairness**, and **transparency**. It details a shareholder proposal requesting an independent AI committee for risk oversight, which the board rejected, citing existing decentralized risk assessment processes at the subsidiary level that already include emerging technology risks. The document also mentions ethical guidelines for AI emphasizing transparency, fairness, and human oversight, and a risk management framework that incorporates AI risks into annual reviews, demonstrating existing governance and oversight mechanisms.",
          "title": "DEF 14A Proxy Statement - AI Governance Proposal & Board Response",
          "url": "https://sec.gov/Archives/edgar/data/1067983/000119312525054877/d812428ddef14a.htm"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_005",
          "source_tier": "third_party",
          "summary": "This blog post, \"The Berkshire Enigma - AI Governance Analysis and Shareholder Perspective,\" provides evidence for **external_accountability, fairness, governance, oversight, and transparency**. The analysis highlights Berkshire's existing governance structures, such as its Audit and Governance committees, which are described as developing and recommending risk management strategies. The source also points to the company's reliance on subsidiary risk assessments and annual reviews for operational governance, while advocating for increased transparency in AI use to enable shareholder evaluation of risks, thereby supporting the transparency and external accountability pillars. Furthermore, the blog post references ethical guidelines and frameworks that emphasize fairness and human oversight, underscoring the need for robust governance and oversight in AI development.",
          "title": "The Berkshire Enigma - AI Governance Analysis and Shareholder Perspective",
          "url": "https://www.forbes.com/sites/bobzukis/2025/03/19/the-berkshire-enigmaare-boards-about-to-make-the-same-mistakes-on-artificial-intelligence-that-they-made-on-cybersecurity/"
        }
      ],
      "score": 1,
      "source_count": 2
    },
    "fairness": {
      "best_evidence_type": "POLICY",
      "display_name": "Fairness & Bias Mitigation",
      "evidence_count": 4,
      "findings": "Ethical guidelines for AI within the company emphasize fairness.",
      "max_score": 2,
      "path_to_improvement": "Publish bias testing results, outcome monitoring, or vendor fairness certifications.",
      "relevant_sources": [
        {
          "artifact_type": "proxy_statement",
          "source_id": "src_001",
          "source_tier": "authority",
          "summary": "This proxy statement provides evidence for **governance**, **oversight**, **external_accountability**, **fairness**, and **transparency**. It details a shareholder proposal requesting an independent AI committee for risk oversight, which the board rejected, citing existing decentralized risk assessment processes at the subsidiary level that already include emerging technology risks. The document also mentions ethical guidelines for AI emphasizing transparency, fairness, and human oversight, and a risk management framework that incorporates AI risks into annual reviews, demonstrating existing governance and oversight mechanisms.",
          "title": "DEF 14A Proxy Statement - AI Governance Proposal & Board Response",
          "url": "https://sec.gov/Archives/edgar/data/1067983/000119312525054877/d812428ddef14a.htm"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_005",
          "source_tier": "third_party",
          "summary": "This blog post, \"The Berkshire Enigma - AI Governance Analysis and Shareholder Perspective,\" provides evidence for **external_accountability, fairness, governance, oversight, and transparency**. The analysis highlights Berkshire's existing governance structures, such as its Audit and Governance committees, which are described as developing and recommending risk management strategies. The source also points to the company's reliance on subsidiary risk assessments and annual reviews for operational governance, while advocating for increased transparency in AI use to enable shareholder evaluation of risks, thereby supporting the transparency and external accountability pillars. Furthermore, the blog post references ethical guidelines and frameworks that emphasize fairness and human oversight, underscoring the need for robust governance and oversight in AI development.",
          "title": "The Berkshire Enigma - AI Governance Analysis and Shareholder Perspective",
          "url": "https://www.forbes.com/sites/bobzukis/2025/03/19/the-berkshire-enigmaare-boards-about-to-make-the-same-mistakes-on-artificial-intelligence-that-they-made-on-cybersecurity/"
        }
      ],
      "score": 1,
      "source_count": 2
    },
    "governance": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Governance & Accountability",
      "evidence_count": 64,
      "findings": "The company's governance framework includes decentralized risk assessment processes at the subsidiary level that incorporate emerging technology risks, supported by ethical guidelines and a risk management framework. Policy documents mandate annual risk assessments, data analytics for compliance, and due diligence for data protection, establishing governance for technological risks including AI. Governance structures, such as Audit and Governance committees, develop risk management strategies, and human representatives retain final decision-making authority in AI use. Strategic investments, AI leadership roles, and internal capabilities demonstrate decision-making and accountability for AI strategy and implementation across operations.",
      "max_score": 2,
      "path_to_improvement": null,
      "relevant_sources": [
        {
          "artifact_type": "proxy_statement",
          "source_id": "src_001",
          "source_tier": "authority",
          "summary": "This proxy statement provides evidence for **governance**, **oversight**, **external_accountability**, **fairness**, and **transparency**. It details a shareholder proposal requesting an independent AI committee for risk oversight, which the board rejected, citing existing decentralized risk assessment processes at the subsidiary level that already include emerging technology risks. The document also mentions ethical guidelines for AI emphasizing transparency, fairness, and human oversight, and a risk management framework that incorporates AI risks into annual reviews, demonstrating existing governance and oversight mechanisms.",
          "title": "DEF 14A Proxy Statement - AI Governance Proposal & Board Response",
          "url": "https://sec.gov/Archives/edgar/data/1067983/000119312525054877/d812428ddef14a.htm"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_002",
          "source_tier": "company_owned",
          "summary": "This policy document, \"Prohibited Business Practices Policy - December 2024,\" provides evidence for the **governance** and **privacy** pillars of responsible AI. It mandates annual risk assessments for subsidiaries to identify and manage external risks, including those posed by artificial intelligence, and requires the use of data analytics to monitor compliance risks and assess emerging technology impacts. The policy also mandates due diligence for data protection and establishes governance for managing technological risks, including AI, supporting its relevance to both pillars.",
          "title": "Prohibited Business Practices Policy - December 2024",
          "url": "https://berkshirehathaway.com/govern/pbpp-2024dec.pdf"
        },
        {
          "artifact_type": "sec_filing",
          "source_id": "src_003",
          "source_tier": "authority",
          "summary": "This Form 10-K report provides evidence for the **governance** and **privacy** pillars of responsible AI. It supports governance by detailing Berkshire Hathaway's decentralized structure with the CEO as chief risk officer and the Audit Committee's oversight of risk management, alongside discussions of internal estimates and valuation methods that imply decision-making authority and accountability. The report supports the privacy pillar through its acknowledgment of data privacy regulations, security of personal information, and mitigation steps for cyber intrusions and unauthorized access.",
          "title": "Form 10-K - Annual Report Fiscal Year 2024",
          "url": "https://sec.gov/Archives/edgar/data/1067983/000095017025025210/brka-20241231.htm"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_005",
          "source_tier": "third_party",
          "summary": "This blog post, \"The Berkshire Enigma - AI Governance Analysis and Shareholder Perspective,\" provides evidence for **external_accountability, fairness, governance, oversight, and transparency**. The analysis highlights Berkshire's existing governance structures, such as its Audit and Governance committees, which are described as developing and recommending risk management strategies. The source also points to the company's reliance on subsidiary risk assessments and annual reviews for operational governance, while advocating for increased transparency in AI use to enable shareholder evaluation of risks, thereby supporting the transparency and external accountability pillars. Furthermore, the blog post references ethical guidelines and frameworks that emphasize fairness and human oversight, underscoring the need for robust governance and oversight in AI development.",
          "title": "The Berkshire Enigma - AI Governance Analysis and Shareholder Perspective",
          "url": "https://www.forbes.com/sites/bobzukis/2025/03/19/the-berkshire-enigmaare-boards-about-to-make-the-same-mistakes-on-artificial-intelligence-that-they-made-on-cybersecurity/"
        },
        {
          "artifact_type": "press_release",
          "source_id": "src_007",
          "source_tier": "third_party",
          "summary": "This press release provides evidence for **transparency** and **governance** by detailing the data sources and model inputs used by Zesty.ai's climate risk analytics platform, including aerial imagery, weather, and real estate data. It also supports **explainability** by describing how the Z-FIRE model derives property-level risk scores based on extensive training data and loss history. The announcement highlights the proprietary nature of the data and model building, implying data governance practices.",
          "title": "Berkshire Hathaway Homestate Companies Selects Zesty.ai for Climate Risk Analytics",
          "url": "https://iireporter.com/berkshire-hathaway-homestate-selects-zesty-ai-for-climate-risk-analysis"
        },
        {
          "artifact_type": "press_release",
          "source_id": "src_008",
          "source_tier": "third_party",
          "summary": "This press release provides evidence for the **governance** and **transparency** pillars of responsible AI. It details the use of AI and computer vision for climate risk assessment, clarifying the system's purpose and how it derives property-specific risk scores from aerial imagery and vegetation factors. Furthermore, the press release mentions proprietary data and AI model training, indicating governance over data and AI development.",
          "title": "Zesty.ai Partnership Details - Berkshire Hathaway Homestate AI Climate Risk",
          "url": "https://zesty.ai/resource/zesty-ai-has-been-selected-by-the-berkshire-hathaway-homestate-companies-for-ai-driven-climate-risk-analytics"
        },
        {
          "artifact_type": "press_release",
          "source_id": "src_010",
          "source_tier": "third_party",
          "summary": "This press release provides evidence for the **governance** and **transparency** pillars of responsible AI. It describes the implementation of an AI suite for claims processing, highlighting the use of AI and machine learning to analyze data and provide insights. While the press release details the capabilities and use cases of the AI, it also clarifies that human representatives retain final decision-making authority, indicating a governance structure for AI use.",
          "title": "Berkshire Hathaway Homestate Companies Adopts CLARA Analytics Suite",
          "url": "https://claraanalytics.com/news/berkshire-hathaway-homestate-companies-embraces-ai-with-adoption-of-entire-clara-analytics-produ"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_011",
          "source_tier": "third_party",
          "summary": "This blog post, \"Artificial Intelligence at GEICO - Computer Vision and Fraud Detection,\" provides evidence for the **governance** and **transparency** pillars of responsible AI. The post describes GEICO's AI applications for claims processing and fraud detection, which implies the existence of policies governing data use and system objectives, thus supporting governance. Furthermore, the detailed explanation of AI capabilities and use cases, including the mention of training data, demonstrates transparency by outlining how the AI systems function.",
          "title": "Artificial Intelligence at GEICO - Computer Vision and Fraud Detection",
          "url": "https://emerj.com/artificial-intelligence-at-geico-two-use-cases"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_015",
          "source_tier": "third_party",
          "summary": "This blog post provides evidence for governance, oversight, privacy, and transparency. It supports governance by describing specific AI capabilities like image analysis for threat detection, establishing a standard for protection. Oversight is evidenced through the description of AI capabilities, data monitoring, and automated/manual remediation, indicating operational execution of security controls. The post also implies privacy and transparency by detailing AI use cases like triage and LLM-powered campaign analysis, which involve data use policies and automated analysis with feedback loops.",
          "title": "Abnormal Security 2025 - AI-Driven Behavioral Threat Detection Evolution",
          "url": "https://abnormal.ai/blog/transformative-year-for-abnormal-security"
        },
        {
          "artifact_type": "other",
          "source_id": "src_016",
          "source_tier": "third_party",
          "summary": "This third-party report, \"Warren Buffett Compares AI Risks to Nuclear Weapons,\" provides evidence for the **governance** pillar. It highlights concerns about AI leaders' insufficient understanding of AI's trajectory and future implications, suggesting a need for robust governance to manage potential risks. The report also touches on the dual potential of AI for good and harm, which aligns with a governance perspective focused on managing AI's impact.",
          "title": "Warren Buffett Compares AI Risks to Nuclear Weapons",
          "url": "https://finance.yahoo.com/news/warren-buffett-compares-ai-risks-to-those-posed-by-nuclear-weapons-the-genie-is-out-of-the-bottle-122210523.html"
        },
        {
          "artifact_type": "other",
          "source_id": "src_017",
          "source_tier": "third_party",
          "summary": "This third-party report, a January 2026 warning from Warren Buffett, provides evidence for the **governance** pillar. Buffett's comparison of AI's unpredictable trajectory to nuclear weapons, highlighting a lack of human control and evolving risks, directly supports the governance pillar by underscoring the need for robust oversight and management of AI development. His framing of AI risks within a broader context of potential societal crises and his personal commitment to addressing existential threats further reinforce the governance implications discussed.",
          "title": "Buffett Issues Major Warning on AI Dangers Equivalent to Nuclear Weapons",
          "url": "https://news.futunn.com/en/post/67441005/buffett-issues-major-warning-the-dangers-of-ai-are-comparable-to"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_019",
          "source_tier": "third_party",
          "summary": "This blog post provides evidence for the **governance** pillar of responsible AI. It details Berkshire Hathaway Energy's strategic pivot and large-scale $32 billion investment in clean energy infrastructure specifically to meet AI data center demand, demonstrating significant decision-making and execution in their AI strategy. The analysis also highlights the adoption of AI for operational efficiency, risk assessment, and R&D, indicating governance over AI implementation across their operations.",
          "title": "Berkshire's AI Power Play 2025: $32B Clean Energy Infrastructure Strategy",
          "url": "https://enkiai.com/ai-market-intelligence/berkshires-ai-power-play-2025-dominating-clean-energy"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_020",
          "source_tier": "third_party",
          "summary": "This blog post, \"Berkshire Hathaway AI Initiatives for 2025,\" provides evidence for the **governance** pillar of responsible AI. The document details a strategic shift in AI investment and use, including the establishment of AI leadership roles and the building of internal capabilities, which implies decision-making authority and accountability for AI strategy. Furthermore, the discussion of AI partnerships and long-term commitments suggests a developing policy stance and internal governance structures for AI adoption.",
          "title": "Berkshire Hathaway AI Initiatives for 2025: Projects, Strategies, Partnerships",
          "url": "https://enkiai.com/berkshire-hathaway-ai-initiatives-for-2025-key-projects-strategies-and-partnerships"
        }
      ],
      "score": 2,
      "source_count": 13
    },
    "oversight": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Human Oversight & Accountability",
      "evidence_count": 12,
      "findings": "Ethical guidelines for AI emphasize human oversight, and a risk management framework incorporates AI risks into annual reviews. Policy documents mandate annual risk assessments for subsidiaries to identify and manage external risks, including those posed by artificial intelligence. Furthermore, human claims adjusters retain final authority over damage determinations, indicating a human-in-the-loop process for AI use, and operational execution of security controls is described through AI capabilities, data monitoring, and automated/manual remediation.",
      "max_score": 2,
      "path_to_improvement": null,
      "relevant_sources": [
        {
          "artifact_type": "proxy_statement",
          "source_id": "src_001",
          "source_tier": "authority",
          "summary": "This proxy statement provides evidence for **governance**, **oversight**, **external_accountability**, **fairness**, and **transparency**. It details a shareholder proposal requesting an independent AI committee for risk oversight, which the board rejected, citing existing decentralized risk assessment processes at the subsidiary level that already include emerging technology risks. The document also mentions ethical guidelines for AI emphasizing transparency, fairness, and human oversight, and a risk management framework that incorporates AI risks into annual reviews, demonstrating existing governance and oversight mechanisms.",
          "title": "DEF 14A Proxy Statement - AI Governance Proposal & Board Response",
          "url": "https://sec.gov/Archives/edgar/data/1067983/000119312525054877/d812428ddef14a.htm"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_002",
          "source_tier": "company_owned",
          "summary": "This policy document, \"Prohibited Business Practices Policy - December 2024,\" provides evidence for the **governance** and **privacy** pillars of responsible AI. It mandates annual risk assessments for subsidiaries to identify and manage external risks, including those posed by artificial intelligence, and requires the use of data analytics to monitor compliance risks and assess emerging technology impacts. The policy also mandates due diligence for data protection and establishes governance for managing technological risks, including AI, supporting its relevance to both pillars.",
          "title": "Prohibited Business Practices Policy - December 2024",
          "url": "https://berkshirehathaway.com/govern/pbpp-2024dec.pdf"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_005",
          "source_tier": "third_party",
          "summary": "This blog post, \"The Berkshire Enigma - AI Governance Analysis and Shareholder Perspective,\" provides evidence for **external_accountability, fairness, governance, oversight, and transparency**. The analysis highlights Berkshire's existing governance structures, such as its Audit and Governance committees, which are described as developing and recommending risk management strategies. The source also points to the company's reliance on subsidiary risk assessments and annual reviews for operational governance, while advocating for increased transparency in AI use to enable shareholder evaluation of risks, thereby supporting the transparency and external accountability pillars. Furthermore, the blog post references ethical guidelines and frameworks that emphasize fairness and human oversight, underscoring the need for robust governance and oversight in AI development.",
          "title": "The Berkshire Enigma - AI Governance Analysis and Shareholder Perspective",
          "url": "https://www.forbes.com/sites/bobzukis/2025/03/19/the-berkshire-enigmaare-boards-about-to-make-the-same-mistakes-on-artificial-intelligence-that-they-made-on-cybersecurity/"
        },
        {
          "artifact_type": "other",
          "source_id": "src_012",
          "source_tier": "third_party",
          "summary": "This announcement about GEICO's deployment of Tractable AI for vehicle damage assessment provides evidence for the **oversight** and **transparency** pillars. It supports oversight by explicitly mentioning that human claims adjusters retain final authority over damage determinations, indicating a human-in-the-loop process. The source also supports transparency by describing the AI's use case in predicting vehicle status and analyzing damage photos.",
          "title": "GEICO Deploying Tractable AI for Vehicle Damage Assessment",
          "url": "https://sofi.com/blog/geico-will-use-ai-speed-claims"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_015",
          "source_tier": "third_party",
          "summary": "This blog post provides evidence for governance, oversight, privacy, and transparency. It supports governance by describing specific AI capabilities like image analysis for threat detection, establishing a standard for protection. Oversight is evidenced through the description of AI capabilities, data monitoring, and automated/manual remediation, indicating operational execution of security controls. The post also implies privacy and transparency by detailing AI use cases like triage and LLM-powered campaign analysis, which involve data use policies and automated analysis with feedback loops.",
          "title": "Abnormal Security 2025 - AI-Driven Behavioral Threat Detection Evolution",
          "url": "https://abnormal.ai/blog/transformative-year-for-abnormal-security"
        }
      ],
      "score": 2,
      "source_count": 5
    },
    "privacy": {
      "best_evidence_type": "POLICY",
      "display_name": "Privacy & Security",
      "evidence_count": 9,
      "findings": "Policy documents mandate due diligence for data protection. Annual reports acknowledge data privacy regulations, security of personal information, and mitigation steps for cyber intrusions and unauthorized access. Additionally, blog posts detail AI use cases that involve data use policies.",
      "max_score": 2,
      "path_to_improvement": "Publish AI-specific privacy impact assessments or data handling procedures.",
      "relevant_sources": [
        {
          "artifact_type": "policy",
          "source_id": "src_002",
          "source_tier": "company_owned",
          "summary": "This policy document, \"Prohibited Business Practices Policy - December 2024,\" provides evidence for the **governance** and **privacy** pillars of responsible AI. It mandates annual risk assessments for subsidiaries to identify and manage external risks, including those posed by artificial intelligence, and requires the use of data analytics to monitor compliance risks and assess emerging technology impacts. The policy also mandates due diligence for data protection and establishes governance for managing technological risks, including AI, supporting its relevance to both pillars.",
          "title": "Prohibited Business Practices Policy - December 2024",
          "url": "https://berkshirehathaway.com/govern/pbpp-2024dec.pdf"
        },
        {
          "artifact_type": "sec_filing",
          "source_id": "src_003",
          "source_tier": "authority",
          "summary": "This Form 10-K report provides evidence for the **governance** and **privacy** pillars of responsible AI. It supports governance by detailing Berkshire Hathaway's decentralized structure with the CEO as chief risk officer and the Audit Committee's oversight of risk management, alongside discussions of internal estimates and valuation methods that imply decision-making authority and accountability. The report supports the privacy pillar through its acknowledgment of data privacy regulations, security of personal information, and mitigation steps for cyber intrusions and unauthorized access.",
          "title": "Form 10-K - Annual Report Fiscal Year 2024",
          "url": "https://sec.gov/Archives/edgar/data/1067983/000095017025025210/brka-20241231.htm"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_015",
          "source_tier": "third_party",
          "summary": "This blog post provides evidence for governance, oversight, privacy, and transparency. It supports governance by describing specific AI capabilities like image analysis for threat detection, establishing a standard for protection. Oversight is evidenced through the description of AI capabilities, data monitoring, and automated/manual remediation, indicating operational execution of security controls. The post also implies privacy and transparency by detailing AI use cases like triage and LLM-powered campaign analysis, which involve data use policies and automated analysis with feedback loops.",
          "title": "Abnormal Security 2025 - AI-Driven Behavioral Threat Detection Evolution",
          "url": "https://abnormal.ai/blog/transformative-year-for-abnormal-security"
        }
      ],
      "score": 1,
      "source_count": 3
    },
    "transparency": {
      "best_evidence_type": "POLICY",
      "display_name": "Transparency",
      "evidence_count": 39,
      "findings": "The company's ethical guidelines for AI emphasize transparency. Documentation and press releases describe the design, capabilities, methodology, and intended use cases of various AI systems, including those for climate risk analytics, wildfire risk assessment, claims processing, fraud detection, and vehicle damage assessment. These materials also clarify data sources, model inputs, and how AI systems derive specific risk scores or operate, including automated remediation functions and data use policies for AI applications.",
      "max_score": 2,
      "path_to_improvement": "Publish detailed documentation (model cards, system specs) for AI systems deployed.",
      "relevant_sources": [
        {
          "artifact_type": "proxy_statement",
          "source_id": "src_001",
          "source_tier": "authority",
          "summary": "This proxy statement provides evidence for **governance**, **oversight**, **external_accountability**, **fairness**, and **transparency**. It details a shareholder proposal requesting an independent AI committee for risk oversight, which the board rejected, citing existing decentralized risk assessment processes at the subsidiary level that already include emerging technology risks. The document also mentions ethical guidelines for AI emphasizing transparency, fairness, and human oversight, and a risk management framework that incorporates AI risks into annual reviews, demonstrating existing governance and oversight mechanisms.",
          "title": "DEF 14A Proxy Statement - AI Governance Proposal & Board Response",
          "url": "https://sec.gov/Archives/edgar/data/1067983/000119312525054877/d812428ddef14a.htm"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_005",
          "source_tier": "third_party",
          "summary": "This blog post, \"The Berkshire Enigma - AI Governance Analysis and Shareholder Perspective,\" provides evidence for **external_accountability, fairness, governance, oversight, and transparency**. The analysis highlights Berkshire's existing governance structures, such as its Audit and Governance committees, which are described as developing and recommending risk management strategies. The source also points to the company's reliance on subsidiary risk assessments and annual reviews for operational governance, while advocating for increased transparency in AI use to enable shareholder evaluation of risks, thereby supporting the transparency and external accountability pillars. Furthermore, the blog post references ethical guidelines and frameworks that emphasize fairness and human oversight, underscoring the need for robust governance and oversight in AI development.",
          "title": "The Berkshire Enigma - AI Governance Analysis and Shareholder Perspective",
          "url": "https://www.forbes.com/sites/bobzukis/2025/03/19/the-berkshire-enigmaare-boards-about-to-make-the-same-mistakes-on-artificial-intelligence-that-they-made-on-cybersecurity/"
        },
        {
          "artifact_type": "press_release",
          "source_id": "src_007",
          "source_tier": "third_party",
          "summary": "This press release provides evidence for **transparency** and **governance** by detailing the data sources and model inputs used by Zesty.ai's climate risk analytics platform, including aerial imagery, weather, and real estate data. It also supports **explainability** by describing how the Z-FIRE model derives property-level risk scores based on extensive training data and loss history. The announcement highlights the proprietary nature of the data and model building, implying data governance practices.",
          "title": "Berkshire Hathaway Homestate Companies Selects Zesty.ai for Climate Risk Analytics",
          "url": "https://iireporter.com/berkshire-hathaway-homestate-selects-zesty-ai-for-climate-risk-analysis"
        },
        {
          "artifact_type": "press_release",
          "source_id": "src_008",
          "source_tier": "third_party",
          "summary": "This press release provides evidence for the **governance** and **transparency** pillars of responsible AI. It details the use of AI and computer vision for climate risk assessment, clarifying the system's purpose and how it derives property-specific risk scores from aerial imagery and vegetation factors. Furthermore, the press release mentions proprietary data and AI model training, indicating governance over data and AI development.",
          "title": "Zesty.ai Partnership Details - Berkshire Hathaway Homestate AI Climate Risk",
          "url": "https://zesty.ai/resource/zesty-ai-has-been-selected-by-the-berkshire-hathaway-homestate-companies-for-ai-driven-climate-risk-analytics"
        },
        {
          "artifact_type": "other",
          "source_id": "src_009",
          "source_tier": "third_party",
          "summary": "This third-party report on Berkshire Hathaway's partnership with Zesty.ai provides evidence for the **transparency** pillar. The report details the Z-FIRE wildfire risk model's capabilities, methodology, and how it functions, including its regional and property-specific risk scoring with explanations of risk factors. This information supports transparency by describing the AI system's design, intended use case for risk selection, and its ability to inform users about climate impact.",
          "title": "Berkshire Hathaway Extends Zesty.ai Partnership - Wildfire Risk Expansion",
          "url": "https://reinsurancene.ws/berkshire-hathaway-extends-partnership-with-zesty-ai"
        },
        {
          "artifact_type": "press_release",
          "source_id": "src_010",
          "source_tier": "third_party",
          "summary": "This press release provides evidence for the **governance** and **transparency** pillars of responsible AI. It describes the implementation of an AI suite for claims processing, highlighting the use of AI and machine learning to analyze data and provide insights. While the press release details the capabilities and use cases of the AI, it also clarifies that human representatives retain final decision-making authority, indicating a governance structure for AI use.",
          "title": "Berkshire Hathaway Homestate Companies Adopts CLARA Analytics Suite",
          "url": "https://claraanalytics.com/news/berkshire-hathaway-homestate-companies-embraces-ai-with-adoption-of-entire-clara-analytics-produ"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_011",
          "source_tier": "third_party",
          "summary": "This blog post, \"Artificial Intelligence at GEICO - Computer Vision and Fraud Detection,\" provides evidence for the **governance** and **transparency** pillars of responsible AI. The post describes GEICO's AI applications for claims processing and fraud detection, which implies the existence of policies governing data use and system objectives, thus supporting governance. Furthermore, the detailed explanation of AI capabilities and use cases, including the mention of training data, demonstrates transparency by outlining how the AI systems function.",
          "title": "Artificial Intelligence at GEICO - Computer Vision and Fraud Detection",
          "url": "https://emerj.com/artificial-intelligence-at-geico-two-use-cases"
        },
        {
          "artifact_type": "other",
          "source_id": "src_012",
          "source_tier": "third_party",
          "summary": "This announcement about GEICO's deployment of Tractable AI for vehicle damage assessment provides evidence for the **oversight** and **transparency** pillars. It supports oversight by explicitly mentioning that human claims adjusters retain final authority over damage determinations, indicating a human-in-the-loop process. The source also supports transparency by describing the AI's use case in predicting vehicle status and analyzing damage photos.",
          "title": "GEICO Deploying Tractable AI for Vehicle Damage Assessment",
          "url": "https://sofi.com/blog/geico-will-use-ai-speed-claims"
        },
        {
          "artifact_type": "other",
          "source_id": "src_014",
          "source_tier": "third_party",
          "summary": "This third-party report on Marmon Holdings' deployment of Abnormal's AI-powered email security provides evidence for **explainability** and **transparency**. The report describes the AI's capability to learn and understand communications, including its ability to explain malicious content, which supports explainability. Furthermore, the mention of the AI's automated remediation functions supports transparency by detailing how the system operates.",
          "title": "Marmon Holdings Secures 120+ Networks with Abnormal Security AI",
          "url": "https://abnormal.ai/resources/marmon"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_015",
          "source_tier": "third_party",
          "summary": "This blog post provides evidence for governance, oversight, privacy, and transparency. It supports governance by describing specific AI capabilities like image analysis for threat detection, establishing a standard for protection. Oversight is evidenced through the description of AI capabilities, data monitoring, and automated/manual remediation, indicating operational execution of security controls. The post also implies privacy and transparency by detailing AI use cases like triage and LLM-powered campaign analysis, which involve data use policies and automated analysis with feedback loops.",
          "title": "Abnormal Security 2025 - AI-Driven Behavioral Threat Detection Evolution",
          "url": "https://abnormal.ai/blog/transformative-year-for-abnormal-security"
        }
      ],
      "score": 1,
      "source_count": 10
    }
  },
  "published_at": "2026-02-23T21:44:44Z",
  "run_id": "20260124_003317_7260",
  "schema_version": "1.0",
  "summary": {
    "key_gaps": [],
    "key_strengths": [
      "Human Oversight & Accountability",
      "Governance & Accountability"
    ],
    "overall_findings": "Evidence for Berkshire Hathaway's responsible AI practices is documented at both operational and policy levels across all 7 evaluated pillars. Operational practices include ethical guidelines for AI emphasizing human oversight and a risk management framework that incorporates AI risks into annual reviews. Governance disclosures also note the board's rejection of a shareholder proposal for an independent AI committee, citing existing decentralized risk assessment processes. Policy-level evidence is present for transparency, fairness, explainability, privacy, and external accountability, with disclosures such as privacy policy documents mandating due diligence for data protection and reports describing AI's capability to explain malicious content. These findings are based on a review of 22 publicly available sources.",
    "pillars_operational": 2,
    "pillars_policy_only": 5,
    "pillars_with_evidence": 7,
    "pillars_without_evidence": 0,
    "total_evidence_items": 98,
    "total_sources_used": 16
  }
}
