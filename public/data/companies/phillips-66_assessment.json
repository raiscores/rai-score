{
  "aggregate": {
    "max_possible_score": 14,
    "percent_score": 28.6,
    "star_display": "★★",
    "star_rating": 2,
    "total_score": 4
  },
  "company": "Phillips 66",
  "company_slug": "phillips-66",
  "evidence_breakdown": {
    "by_type": {
      "NARRATIVE": 1,
      "OPERATIONAL": 1,
      "POLICY": 5
    }
  },
  "pillar_scores": {
    "explainability": {
      "best_evidence_type": null,
      "display_name": "Explainability",
      "evidence_count": 0,
      "findings": null,
      "max_score": 2,
      "path_to_improvement": "Document how explanations are provided to users affected by AI decisions.",
      "relevant_sources": [],
      "score": 0,
      "source_count": 0
    },
    "external_accountability": {
      "best_evidence_type": "POLICY",
      "display_name": "Public Commitments & External Audits",
      "evidence_count": 1,
      "findings": "The company mentions input from independent experts regarding AI governance and risks. This indicates a review process that extends beyond internal stakeholders.",
      "max_score": 2,
      "path_to_improvement": "Publish third-party audit results, certifications, or regulatory compliance documentation.",
      "relevant_sources": [
        {
          "artifact_type": "proxy_statement",
          "source_id": "src_002",
          "source_tier": "authority",
          "summary": "This proxy statement provides evidence for **governance** and **external accountability**. It demonstrates governance by detailing the board's oversight of technology security, cybersecurity, and artificial intelligence risks, including educational initiatives for board members on these topics. The mention of input from independent experts regarding AI governance and risks supports external accountability by indicating a review process beyond internal stakeholders.",
          "title": "Phillips 66 2025 Definitive Proxy Statement",
          "url": "https://sec.gov/Archives/edgar/data/1534701/000153470125000088/psx-2025definitiveproxysta.pdf"
        }
      ],
      "score": 1,
      "source_count": 1
    },
    "fairness": {
      "best_evidence_type": "POLICY",
      "display_name": "Fairness & Bias Mitigation",
      "evidence_count": 1,
      "findings": "A policy document describes commitments to prevent discrimination and mitigate bias. This policy supports the company's approach to fairness in AI practices.",
      "max_score": 2,
      "path_to_improvement": "Publish bias testing results, outcome monitoring, or vendor fairness certifications.",
      "relevant_sources": [
        {
          "artifact_type": "policy",
          "source_id": "src_003",
          "source_tier": "third_party",
          "summary": "This policy document, the \"Phillips 66 2024 Sustainability and People Report,\" provides evidence for fairness, governance, privacy, and transparency. It supports governance by explicitly naming an \"AI Governance Board\" that monitors and approves generative AI use, and by referencing AI/ML use cases and principles. The report also supports fairness and governance by describing a policy with commitments to prevent discrimination and mitigate bias, and it supports privacy by outlining commitments to prevent privacy violations.",
          "title": "Phillips 66 2024 Sustainability and People Report",
          "url": "https://climindstorage123.blob.core.windows.net/climind/upload/2025-01-26/3841d792-c0fc-4c40-9153-f0c5a1bbd340.pdf"
        }
      ],
      "score": 1,
      "source_count": 1
    },
    "governance": {
      "best_evidence_type": "POLICY",
      "display_name": "Governance & Accountability",
      "evidence_count": 7,
      "findings": "The company details the board's oversight of artificial intelligence risks, including educational initiatives for board members. An AI Governance Board is explicitly named to monitor and approve generative AI use, and AI/ML use cases and principles are referenced. Furthermore, a policy describes commitments to prevent discrimination and mitigate bias, and the company indicates consideration of policy and oversight mechanisms for AI technology management.",
      "max_score": 2,
      "path_to_improvement": "Name an AI governance body with defined mandate covering all AI use.",
      "relevant_sources": [
        {
          "artifact_type": "proxy_statement",
          "source_id": "src_002",
          "source_tier": "authority",
          "summary": "This proxy statement provides evidence for **governance** and **external accountability**. It demonstrates governance by detailing the board's oversight of technology security, cybersecurity, and artificial intelligence risks, including educational initiatives for board members on these topics. The mention of input from independent experts regarding AI governance and risks supports external accountability by indicating a review process beyond internal stakeholders.",
          "title": "Phillips 66 2025 Definitive Proxy Statement",
          "url": "https://sec.gov/Archives/edgar/data/1534701/000153470125000088/psx-2025definitiveproxysta.pdf"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_003",
          "source_tier": "third_party",
          "summary": "This policy document, the \"Phillips 66 2024 Sustainability and People Report,\" provides evidence for fairness, governance, privacy, and transparency. It supports governance by explicitly naming an \"AI Governance Board\" that monitors and approves generative AI use, and by referencing AI/ML use cases and principles. The report also supports fairness and governance by describing a policy with commitments to prevent discrimination and mitigate bias, and it supports privacy by outlining commitments to prevent privacy violations.",
          "title": "Phillips 66 2024 Sustainability and People Report",
          "url": "https://climindstorage123.blob.core.windows.net/climind/upload/2025-01-26/3841d792-c0fc-4c40-9153-f0c5a1bbd340.pdf"
        },
        {
          "artifact_type": "sec_filing",
          "source_id": "src_004",
          "source_tier": "authority",
          "summary": "The Phillips 66 Form 10-K Annual Report (2024) provides evidence for the **governance** pillar of responsible AI. The report's mention of \"generative artificial intelligence,\" \"evolving government regulation,\" and \"development and deployment\" indicates that the company is considering policy and oversight mechanisms for AI technology management, aligning with governance principles.",
          "title": "Phillips 66 Form 10-K Annual Report (2024)",
          "url": "https://sec.gov/Archives/edgar/data/1534701/000153470125000074/psx-20241231.htm"
        }
      ],
      "score": 1,
      "source_count": 3
    },
    "oversight": {
      "best_evidence_type": null,
      "display_name": "Human Oversight & Accountability",
      "evidence_count": 0,
      "findings": null,
      "max_score": 2,
      "path_to_improvement": "Document human review processes for AI-assisted decisions (built or vendor AI).",
      "relevant_sources": [],
      "score": 0,
      "source_count": 0
    },
    "privacy": {
      "best_evidence_type": "POLICY",
      "display_name": "Privacy & Security",
      "evidence_count": 1,
      "findings": "A policy document outlines commitments to prevent privacy violations. This demonstrates the company's focus on privacy in its AI practices.",
      "max_score": 2,
      "path_to_improvement": "Publish AI-specific privacy impact assessments or data handling procedures.",
      "relevant_sources": [
        {
          "artifact_type": "policy",
          "source_id": "src_003",
          "source_tier": "third_party",
          "summary": "This policy document, the \"Phillips 66 2024 Sustainability and People Report,\" provides evidence for fairness, governance, privacy, and transparency. It supports governance by explicitly naming an \"AI Governance Board\" that monitors and approves generative AI use, and by referencing AI/ML use cases and principles. The report also supports fairness and governance by describing a policy with commitments to prevent discrimination and mitigate bias, and it supports privacy by outlining commitments to prevent privacy violations.",
          "title": "Phillips 66 2024 Sustainability and People Report",
          "url": "https://climindstorage123.blob.core.windows.net/climind/upload/2025-01-26/3841d792-c0fc-4c40-9153-f0c5a1bbd340.pdf"
        }
      ],
      "score": 1,
      "source_count": 1
    },
    "transparency": {
      "best_evidence_type": "NARRATIVE",
      "display_name": "Transparency",
      "evidence_count": 1,
      "findings": "Sources describe documented transparency practices in 1 source(s). Additional documentation references related practices.",
      "max_score": 2,
      "path_to_improvement": "Document AI systems in use, including vendor/third-party AI tools.",
      "relevant_sources": [
        {
          "artifact_type": "policy",
          "source_id": "src_003",
          "source_tier": "third_party",
          "summary": "This policy document, the \"Phillips 66 2024 Sustainability and People Report,\" provides evidence for fairness, governance, privacy, and transparency. It supports governance by explicitly naming an \"AI Governance Board\" that monitors and approves generative AI use, and by referencing AI/ML use cases and principles. The report also supports fairness and governance by describing a policy with commitments to prevent discrimination and mitigate bias, and it supports privacy by outlining commitments to prevent privacy violations.",
          "title": "Phillips 66 2024 Sustainability and People Report",
          "url": "https://climindstorage123.blob.core.windows.net/climind/upload/2025-01-26/3841d792-c0fc-4c40-9153-f0c5a1bbd340.pdf"
        }
      ],
      "score": 0,
      "source_count": 1
    }
  },
  "published_at": "2026-02-23T21:57:34Z",
  "run_id": "20260203_013313_1a45",
  "schema_version": "1.0",
  "summary": {
    "key_gaps": [
      "Transparency",
      "Explainability",
      "Human Oversight & Accountability"
    ],
    "key_strengths": [],
    "overall_findings": "Phillips 66's published materials detail the board's oversight of artificial intelligence risks, alongside educational initiatives for board members on these risks. These disclosures address 4 of 7 evaluated responsible AI pillars, with policies also describing commitments to prevent discrimination and mitigate bias under fairness, and outlining commitments to prevent privacy violations. Additionally, input from independent experts regarding AI governance and risks is mentioned, and a review process beyond internal stakeholders is indicated. No qualifying public evidence was found for transparency, explainability, and 1 additional pillar, based on a review of 5 publicly available sources.",
    "pillars_operational": 0,
    "pillars_policy_only": 4,
    "pillars_with_evidence": 4,
    "pillars_without_evidence": 3,
    "total_evidence_items": 7,
    "total_sources_used": 3
  }
}
