{
  "aggregate": {
    "max_possible_score": 14,
    "percent_score": 78.6,
    "star_display": "★★★★",
    "star_rating": 4,
    "total_score": 11
  },
  "company": "Philip Morris",
  "company_slug": "philip-morris",
  "evidence_breakdown": {
    "by_type": {
      "NARRATIVE": 4,
      "OPERATIONAL": 8,
      "POLICY": 19
    }
  },
  "pillar_scores": {
    "explainability": {
      "best_evidence_type": "POLICY",
      "display_name": "Explainability",
      "evidence_count": 2,
      "findings": "A Responsible AI workstream aims to mitigate risks related to explainability. Furthermore, a consumer privacy notice describes AI's role in data analysis for segmentation and personalization.",
      "max_score": 2,
      "path_to_improvement": "Publish user-facing explanation interfaces or documented appeal workflows.",
      "relevant_sources": [
        {
          "artifact_type": "blog_post",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This company-owned blog post, \"The state of AI at PMI,\" provides evidence for **explainability, fairness, governance, privacy, and transparency**. The document details PMI's AI strategy, including the launch of a GenAI Hyperscaler platform and a dedicated Responsible AI workstream. This workstream explicitly aims to mitigate risks such as bias amplification, lack of transparency, and explainability, directly supporting the fairness and transparency pillars. Furthermore, the blog post describes a monthly steering committee and a central platform for AI management, demonstrating strong governance practices, and mentions compliance with cybersecurity and privacy regulations, supporting the privacy pillar.",
          "title": "The state of AI at PMI",
          "url": "https://pmi.com/sustainability/case-studies-and-market-stories/the-state-of-ai-at-pmi"
        },
        {
          "artifact_type": "privacy_policy",
          "source_id": "src_005",
          "source_tier": "third_party",
          "summary": "This consumer privacy notice provides evidence for **explainability, governance, oversight, privacy, and transparency**. It supports these pillars by describing AI's role in data analysis for segmentation and personalization, mentioning human intervention for oversight, and detailing data handling practices like consent requirements and deletion policies. The notice also outlines AI use cases for fraud prevention, technical diagnostics, and customer care, demonstrating transparency about automated processing and user rights.",
          "title": "PMI's Consumer Privacy Notice",
          "url": "https://pmiprivacy.com/global/en/consumer"
        }
      ],
      "score": 1,
      "source_count": 2
    },
    "external_accountability": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Public Commitments & External Audits",
      "evidence_count": 1,
      "findings": "A proxy statement mentions assurance provided by an independent third party, PricewaterhouseCoopers SA.",
      "max_score": 2,
      "path_to_improvement": null,
      "relevant_sources": [
        {
          "artifact_type": "proxy_statement",
          "source_id": "src_003",
          "source_tier": "company_owned",
          "summary": "This 2025 proxy statement provides evidence for **governance** and **external accountability**. It supports governance by detailing the Board's oversight of AI risks, the Audit and Risk Committee's reviews, and the Enterprise Risk Management (ERM) Program's accountability for AI risk management. The document also supports external accountability by mentioning assurance provided by an independent third party, PricewaterhouseCoopers SA.",
          "title": "2025 Annual Meeting of Shareholders and Proxy Statement",
          "url": "https://pmi.com/resources/docs/default-source/investor_relation/philip-morris-international-inc-def-14a.pdf"
        }
      ],
      "score": 2,
      "source_count": 1
    },
    "fairness": {
      "best_evidence_type": "POLICY",
      "display_name": "Fairness & Bias Mitigation",
      "evidence_count": 1,
      "findings": "A Responsible AI workstream aims to mitigate risks, including bias amplification.",
      "max_score": 2,
      "path_to_improvement": "Publish bias testing results, outcome monitoring, or vendor fairness certifications.",
      "relevant_sources": [
        {
          "artifact_type": "blog_post",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This company-owned blog post, \"The state of AI at PMI,\" provides evidence for **explainability, fairness, governance, privacy, and transparency**. The document details PMI's AI strategy, including the launch of a GenAI Hyperscaler platform and a dedicated Responsible AI workstream. This workstream explicitly aims to mitigate risks such as bias amplification, lack of transparency, and explainability, directly supporting the fairness and transparency pillars. Furthermore, the blog post describes a monthly steering committee and a central platform for AI management, demonstrating strong governance practices, and mentions compliance with cybersecurity and privacy regulations, supporting the privacy pillar.",
          "title": "The state of AI at PMI",
          "url": "https://pmi.com/sustainability/case-studies-and-market-stories/the-state-of-ai-at-pmi"
        }
      ],
      "score": 1,
      "source_count": 1
    },
    "governance": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Governance & Accountability",
      "evidence_count": 14,
      "findings": "A blog post details PMI's AI strategy, including a GenAI Hyperscaler platform and a Responsible AI workstream. An annual report indicates the company's awareness of and need for governance controls in its AI initiatives. A proxy statement details the Board's oversight of AI risks, Audit and Risk Committee reviews, and the Enterprise Risk Management Program's accountability for AI risk management. Furthermore, a consumer privacy notice details data handling practices, and an audit report details a cross-functional cybersecurity risk program, assessments, cyber defense operations, and Board-level oversight implicitly including AI governance.",
      "max_score": 2,
      "path_to_improvement": null,
      "relevant_sources": [
        {
          "artifact_type": "blog_post",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This company-owned blog post, \"The state of AI at PMI,\" provides evidence for **explainability, fairness, governance, privacy, and transparency**. The document details PMI's AI strategy, including the launch of a GenAI Hyperscaler platform and a dedicated Responsible AI workstream. This workstream explicitly aims to mitigate risks such as bias amplification, lack of transparency, and explainability, directly supporting the fairness and transparency pillars. Furthermore, the blog post describes a monthly steering committee and a central platform for AI management, demonstrating strong governance practices, and mentions compliance with cybersecurity and privacy regulations, supporting the privacy pillar.",
          "title": "The state of AI at PMI",
          "url": "https://pmi.com/sustainability/case-studies-and-market-stories/the-state-of-ai-at-pmi"
        },
        {
          "artifact_type": "sec_filing",
          "source_id": "src_002",
          "source_tier": "authority",
          "summary": "PMI's 2024 Form 10-K Item 1C, a SEC filing, provides evidence for the **governance** and **privacy** pillars of responsible AI. The report highlights risks associated with non-adherence to AI privacy and security laws, and mentions AI capabilities alongside data protection risks, indicating the company's awareness of and need for governance and privacy controls in its AI initiatives.",
          "title": "Form 10-K Annual Report for fiscal year ended December 31, 2024",
          "url": "https://sec.gov/Archives/edgar/data/1413329/000141332925000013/pm-20241231.htm"
        },
        {
          "artifact_type": "proxy_statement",
          "source_id": "src_003",
          "source_tier": "company_owned",
          "summary": "This 2025 proxy statement provides evidence for **governance** and **external accountability**. It supports governance by detailing the Board's oversight of AI risks, the Audit and Risk Committee's reviews, and the Enterprise Risk Management (ERM) Program's accountability for AI risk management. The document also supports external accountability by mentioning assurance provided by an independent third party, PricewaterhouseCoopers SA.",
          "title": "2025 Annual Meeting of Shareholders and Proxy Statement",
          "url": "https://pmi.com/resources/docs/default-source/investor_relation/philip-morris-international-inc-def-14a.pdf"
        },
        {
          "artifact_type": "privacy_policy",
          "source_id": "src_005",
          "source_tier": "third_party",
          "summary": "This consumer privacy notice provides evidence for **explainability, governance, oversight, privacy, and transparency**. It supports these pillars by describing AI's role in data analysis for segmentation and personalization, mentioning human intervention for oversight, and detailing data handling practices like consent requirements and deletion policies. The notice also outlines AI use cases for fraud prevention, technical diagnostics, and customer care, demonstrating transparency about automated processing and user rights.",
          "title": "PMI's Consumer Privacy Notice",
          "url": "https://pmiprivacy.com/global/en/consumer"
        },
        {
          "artifact_type": "audit_report",
          "source_id": "src_013",
          "source_tier": "third_party",
          "summary": "This audit report, \"Philip Morris International Inc. 10-K Cybersecurity GRC - Tracker Report,\" provides evidence for the **governance** and **privacy** pillars of responsible AI. The report supports the governance pillar by detailing PMI's cross-functional cybersecurity risk program, threat and maturity assessments, cyber defense operations, and Board-level oversight, which implicitly includes AI governance. It supports the privacy pillar by explicitly mentioning AI regulations and detailing privacy requirements for AI, indicating a policy commitment to compliance and adherence to privacy standards.",
          "title": "Philip Morris International Inc. 10-K Cybersecurity GRC - Tracker Report",
          "url": "https://board-cybersecurity.com/annual-reports/tracker/20250206-philip-morris-international-inc-cybersecurity-10k"
        }
      ],
      "score": 2,
      "source_count": 5
    },
    "oversight": {
      "best_evidence_type": "POLICY",
      "display_name": "Human Oversight & Accountability",
      "evidence_count": 2,
      "findings": "A consumer privacy notice mentions human intervention for oversight in AI data analysis.",
      "max_score": 2,
      "path_to_improvement": "Publish override mechanisms, escalation processes, or appeal workflows.",
      "relevant_sources": [
        {
          "artifact_type": "privacy_policy",
          "source_id": "src_005",
          "source_tier": "third_party",
          "summary": "This consumer privacy notice provides evidence for **explainability, governance, oversight, privacy, and transparency**. It supports these pillars by describing AI's role in data analysis for segmentation and personalization, mentioning human intervention for oversight, and detailing data handling practices like consent requirements and deletion policies. The notice also outlines AI use cases for fraud prevention, technical diagnostics, and customer care, demonstrating transparency about automated processing and user rights.",
          "title": "PMI's Consumer Privacy Notice",
          "url": "https://pmiprivacy.com/global/en/consumer"
        }
      ],
      "score": 1,
      "source_count": 1
    },
    "privacy": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Privacy & Security",
      "evidence_count": 12,
      "findings": "An annual report highlights risks associated with non-adherence to AI privacy and security laws and mentions AI capabilities alongside data protection risks. A consumer privacy notice details data handling practices, including consent requirements and deletion policies. Additionally, an audit report explicitly mentions AI regulations and details privacy requirements for AI, indicating a policy commitment to compliance and adherence to privacy standards.",
      "max_score": 2,
      "path_to_improvement": null,
      "relevant_sources": [
        {
          "artifact_type": "blog_post",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This company-owned blog post, \"The state of AI at PMI,\" provides evidence for **explainability, fairness, governance, privacy, and transparency**. The document details PMI's AI strategy, including the launch of a GenAI Hyperscaler platform and a dedicated Responsible AI workstream. This workstream explicitly aims to mitigate risks such as bias amplification, lack of transparency, and explainability, directly supporting the fairness and transparency pillars. Furthermore, the blog post describes a monthly steering committee and a central platform for AI management, demonstrating strong governance practices, and mentions compliance with cybersecurity and privacy regulations, supporting the privacy pillar.",
          "title": "The state of AI at PMI",
          "url": "https://pmi.com/sustainability/case-studies-and-market-stories/the-state-of-ai-at-pmi"
        },
        {
          "artifact_type": "sec_filing",
          "source_id": "src_002",
          "source_tier": "authority",
          "summary": "PMI's 2024 Form 10-K Item 1C, a SEC filing, provides evidence for the **governance** and **privacy** pillars of responsible AI. The report highlights risks associated with non-adherence to AI privacy and security laws, and mentions AI capabilities alongside data protection risks, indicating the company's awareness of and need for governance and privacy controls in its AI initiatives.",
          "title": "Form 10-K Annual Report for fiscal year ended December 31, 2024",
          "url": "https://sec.gov/Archives/edgar/data/1413329/000141332925000013/pm-20241231.htm"
        },
        {
          "artifact_type": "privacy_policy",
          "source_id": "src_005",
          "source_tier": "third_party",
          "summary": "This consumer privacy notice provides evidence for **explainability, governance, oversight, privacy, and transparency**. It supports these pillars by describing AI's role in data analysis for segmentation and personalization, mentioning human intervention for oversight, and detailing data handling practices like consent requirements and deletion policies. The notice also outlines AI use cases for fraud prevention, technical diagnostics, and customer care, demonstrating transparency about automated processing and user rights.",
          "title": "PMI's Consumer Privacy Notice",
          "url": "https://pmiprivacy.com/global/en/consumer"
        },
        {
          "artifact_type": "audit_report",
          "source_id": "src_013",
          "source_tier": "third_party",
          "summary": "This audit report, \"Philip Morris International Inc. 10-K Cybersecurity GRC - Tracker Report,\" provides evidence for the **governance** and **privacy** pillars of responsible AI. The report supports the governance pillar by detailing PMI's cross-functional cybersecurity risk program, threat and maturity assessments, cyber defense operations, and Board-level oversight, which implicitly includes AI governance. It supports the privacy pillar by explicitly mentioning AI regulations and detailing privacy requirements for AI, indicating a policy commitment to compliance and adherence to privacy standards.",
          "title": "Philip Morris International Inc. 10-K Cybersecurity GRC - Tracker Report",
          "url": "https://board-cybersecurity.com/annual-reports/tracker/20250206-philip-morris-international-inc-cybersecurity-10k"
        }
      ],
      "score": 2,
      "source_count": 4
    },
    "transparency": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Transparency",
      "evidence_count": 13,
      "findings": "A Responsible AI workstream aims to mitigate risks including a lack of transparency. Additionally, a consumer privacy notice outlines AI use cases for fraud prevention, technical diagnostics, and customer care. This notice also demonstrates transparency regarding automated processing and user rights.",
      "max_score": 2,
      "path_to_improvement": null,
      "relevant_sources": [
        {
          "artifact_type": "blog_post",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This company-owned blog post, \"The state of AI at PMI,\" provides evidence for **explainability, fairness, governance, privacy, and transparency**. The document details PMI's AI strategy, including the launch of a GenAI Hyperscaler platform and a dedicated Responsible AI workstream. This workstream explicitly aims to mitigate risks such as bias amplification, lack of transparency, and explainability, directly supporting the fairness and transparency pillars. Furthermore, the blog post describes a monthly steering committee and a central platform for AI management, demonstrating strong governance practices, and mentions compliance with cybersecurity and privacy regulations, supporting the privacy pillar.",
          "title": "The state of AI at PMI",
          "url": "https://pmi.com/sustainability/case-studies-and-market-stories/the-state-of-ai-at-pmi"
        },
        {
          "artifact_type": "privacy_policy",
          "source_id": "src_005",
          "source_tier": "third_party",
          "summary": "This consumer privacy notice provides evidence for **explainability, governance, oversight, privacy, and transparency**. It supports these pillars by describing AI's role in data analysis for segmentation and personalization, mentioning human intervention for oversight, and detailing data handling practices like consent requirements and deletion policies. The notice also outlines AI use cases for fraud prevention, technical diagnostics, and customer care, demonstrating transparency about automated processing and user rights.",
          "title": "PMI's Consumer Privacy Notice",
          "url": "https://pmiprivacy.com/global/en/consumer"
        }
      ],
      "score": 2,
      "source_count": 2
    }
  },
  "published_at": "2026-02-23T21:57:30Z",
  "run_id": "20260203_024351_e5a1",
  "schema_version": "1.0",
  "summary": {
    "key_gaps": [],
    "key_strengths": [
      "Transparency",
      "Privacy & Security",
      "Governance & Accountability",
      "Public Commitments & External Audits"
    ],
    "overall_findings": "Philip Morris' public disclosures address operational practices in transparency, where a Responsible AI workstream aims to mitigate risks such as lack of transparency, and in privacy, where an annual report highlights risks associated with non-adherence to AI privacy and security laws. All 7 evaluated pillars have documented public evidence, with fairness, explainability, and oversight addressed at the policy level. Governance materials detail PMI's AI strategy and the launch of a GenAI Hyperscaler platform. External accountability is also documented through a proxy statement mentioning assurance provided by an independent third party, PricewaterhouseCoopers SA. These findings are based on 14 publicly available sources.",
    "pillars_operational": 4,
    "pillars_policy_only": 3,
    "pillars_with_evidence": 7,
    "pillars_without_evidence": 0,
    "total_evidence_items": 31,
    "total_sources_used": 5
  }
}
