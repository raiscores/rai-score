{
  "aggregate": {
    "max_possible_score": 14,
    "percent_score": 78.6,
    "star_display": "★★★★",
    "star_rating": 4,
    "total_score": 11
  },
  "company": "Adobe",
  "company_slug": "adobe",
  "evidence_breakdown": {
    "by_type": {
      "NARRATIVE": 52,
      "OPERATIONAL": 28,
      "POLICY": 87
    }
  },
  "pillar_scores": {
    "explainability": {
      "best_evidence_type": null,
      "display_name": "Explainability",
      "evidence_count": 0,
      "findings": null,
      "max_score": 2,
      "path_to_improvement": "Document how explanations are provided to users affected by AI decisions.",
      "relevant_sources": [],
      "score": 0,
      "source_count": 0
    },
    "external_accountability": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Public Commitments & External Audits",
      "evidence_count": 15,
      "findings": "Adobe's reports discuss AI regulations and compliance, and policy documents reference adherence to external regulatory frameworks like NIST and the EU AI Act. The company discusses legal indemnification for AI-generated content to ensure commercial safety and supports external accountability through indemnification policies for enterprise users and a commitment to legally licensed training data.",
      "max_score": 2,
      "path_to_improvement": null,
      "relevant_sources": [
        {
          "artifact_type": "policy",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This company-owned policy document, \"Responsible AI & Ethical Development - Adobe for Business,\" provides evidence for **external_accountability, fairness, governance, and oversight**. The policy outlines specific mechanisms such as establishing governance processes, requiring AI Impact Assessments to identify harmful biases, and creating a diverse AI Ethics Review Board for oversight, all of which demonstrate a commitment to responsible AI development and deployment. The document also explicitly lists training, testing, impact assessments, and diverse human oversight as key pillars, further supporting these responsible AI principles.",
          "title": "Responsible AI & Ethical Development - Adobe for Business",
          "url": "https://business.adobe.com/ai/responsible-ai.html"
        },
        {
          "artifact_type": "sec_filing",
          "source_id": "src_005",
          "source_tier": "authority",
          "summary": "This 2024 Annual Report (Form 10-K) provides evidence for **governance**, **transparency**, **external accountability**, and **fairness**. The report details Adobe's AI offerings like Acrobat AI Assistant and Adobe Firefly Services, indicating transparency in their capabilities and use cases. It also references a commitment to AI Ethics principles, including accountability and responsibility, and discusses AI regulations and compliance, supporting external accountability. Furthermore, the report mentions concerns about \"harmful bias\" and a commitment to \"product equity,\" demonstrating attention to fairness.",
          "title": "FORM 10-K ADOBE INC. - 2024 Annual Report",
          "url": "https://sec.gov/Archives/edgar/data/796343/000079634325000050/adbe2024annualreporta.pdf"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_012",
          "source_tier": "company_owned",
          "summary": "This policy document, \"Responsible AI adoption framework | The AI inflection point guide,\" provides evidence for **governance**, **external accountability**, **fairness**, and **transparency**. It details the establishment and empowerment of governance teams, vendor evaluation, and adherence to external regulatory frameworks like NIST and the EU AI Act, supporting governance and external accountability. Furthermore, the document describes testing for bias in AI products and the operational use of content filters, demonstrating efforts towards fairness and transparency.",
          "title": "Responsible AI adoption framework | The AI inflection point guide",
          "url": "https://business.adobe.com/resources/sdk/the-ai-inflection-point.html"
        },
        {
          "artifact_type": "other",
          "source_id": "src_016",
          "source_tier": "third_party",
          "summary": "This MarTech report, based on a Bloomberg investigation, provides evidence for **external_accountability**, **governance**, and **transparency**. It supports external_accountability and governance by discussing Adobe's legal indemnification for AI-generated content, which aims to ensure commercial safety. The report also highlights transparency concerns, referencing regulatory requirements like the AI Act for model training data and customer apprehension about generative AI training data composition.",
          "title": "Legal risks loom for Firefly users after Adobe's AI image tool training exposed",
          "url": "https://martech.org/legal-risks-loom-for-firefly-users-after-adobes-ai-image-tool-training-exposed"
        },
        {
          "artifact_type": "technical_paper",
          "source_id": "src_017",
          "source_tier": "third_party",
          "summary": "This technical paper on Adobe's AI approach provides evidence for **external_accountability**, **fairness**, **governance**, **oversight**, **privacy**, and **transparency**. It supports **external_accountability** through indemnification policies for enterprise users and a commitment to legally licensed training data. **Governance** is evidenced by mentions of AI governance training, AI architect designations, and formal AI policies. The paper also touches on **transparency** by discussing the need for clarity in generative AI pricing and capabilities, and **oversight** is implied through the evolution of reviewers to validators for AI outputs. While not explicitly detailed, the focus on legally grounded training data and secure procurement processes suggests considerations for **privacy**.",
          "title": "Adobe's Legally Grounded AI Model Offers a Blueprint for Responsible Innovation",
          "url": "https://complexdiscovery.com/adobes-legally-grounded-ai-model-offers-a-blueprint-for-responsible-innovation"
        }
      ],
      "score": 2,
      "source_count": 5
    },
    "fairness": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Fairness & Bias Mitigation",
      "evidence_count": 27,
      "findings": "Adobe's policy documents require AI Impact Assessments to identify harmful biases and focus on evaluating AI impact, inclusiveness, and bias assessment. Technical papers describe debiasing efforts, bias reduction, and ensuring diverse representation through adversarial testing and human impact assessment frameworks. The company conducts testing to reduce bias and harmful outcomes, and outlines mechanisms for bias remediation and feedback.",
      "max_score": 2,
      "path_to_improvement": null,
      "relevant_sources": [
        {
          "artifact_type": "policy",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This company-owned policy document, \"Responsible AI & Ethical Development - Adobe for Business,\" provides evidence for **external_accountability, fairness, governance, and oversight**. The policy outlines specific mechanisms such as establishing governance processes, requiring AI Impact Assessments to identify harmful biases, and creating a diverse AI Ethics Review Board for oversight, all of which demonstrate a commitment to responsible AI development and deployment. The document also explicitly lists training, testing, impact assessments, and diverse human oversight as key pillars, further supporting these responsible AI principles.",
          "title": "Responsible AI & Ethical Development - Adobe for Business",
          "url": "https://business.adobe.com/ai/responsible-ai.html"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_002",
          "source_tier": "company_owned",
          "summary": "This policy document, \"Our Commitment to AI Ethics - Adobe,\" provides evidence for the **fairness** and **governance** pillars of responsible AI. It supports fairness by focusing on evaluating AI impact, inclusiveness, and assessing bias. The document demonstrates strong governance through its detailed operational processes, including AI Impact Assessments, an AI Ethics Review Board, assigned accountability for AI ethics to leaders, and proactive harm mitigation strategies.",
          "title": "Our Commitment to AI Ethics - Adobe",
          "url": "https://adobe.com/cc-shared/assets/pdf/ai-ethics/adobe-ai-ethics-principles.pdf"
        },
        {
          "artifact_type": "sec_filing",
          "source_id": "src_005",
          "source_tier": "authority",
          "summary": "This 2024 Annual Report (Form 10-K) provides evidence for **governance**, **transparency**, **external accountability**, and **fairness**. The report details Adobe's AI offerings like Acrobat AI Assistant and Adobe Firefly Services, indicating transparency in their capabilities and use cases. It also references a commitment to AI Ethics principles, including accountability and responsibility, and discusses AI regulations and compliance, supporting external accountability. Furthermore, the report mentions concerns about \"harmful bias\" and a commitment to \"product equity,\" demonstrating attention to fairness.",
          "title": "FORM 10-K ADOBE INC. - 2024 Annual Report",
          "url": "https://sec.gov/Archives/edgar/data/796343/000079634325000050/adbe2024annualreporta.pdf"
        },
        {
          "artifact_type": "technical_paper",
          "source_id": "src_007",
          "source_tier": "third_party",
          "summary": "This technical paper from Adobe details their adversarial testing process and a three-tiered human impact assessment framework for mitigating biased and harmful generative AI outputs. The paper provides evidence for **fairness** by describing debiasing efforts, bias reduction, and ensuring diverse representation, as well as for **governance** and **oversight** through its structured approach to assessing and mitigating AI impact before product release, including specific feedback mechanisms and operational safety mechanisms like red teaming.",
          "title": "Reducing biased and harmful outcomes in generative AI",
          "url": "https://adobe.design/stories/leading-design/reducing-biased-and-harmful-outcomes-in-generative-ai"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_008",
          "source_tier": "company_owned",
          "summary": "This Adobe infographic, a company-owned policy document, details a robust AI Ethics governance process involving three institutional bodies: the AI Ethics Committee, AI Ethics Review Board, and AI@Adobe Working Group. The document supports **governance** and **oversight** by outlining a structured review process with specific roles and responsibilities for these bodies, including submission, collaboration, risk mitigation, and repetition. Evidence for **fairness** is found in the mention of conducting testing to reduce bias and harmful outcomes, while the emphasis on AI ethics principles like accountability, responsibility, and transparency, alongside a standardized process, supports the **transparency** pillar.",
          "title": "Building responsible generative AI solutions for the new creative era",
          "url": "https://business.adobe.com/assets/pdfs/resources/infographics/responsible-gen-ai-infographic/building-responsible-generative-ai-solutions-for-the-new-creative-era.pdf"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_011",
          "source_tier": "company_owned",
          "summary": "This Adobe solution brief, \"Generative AI Built for Business,\" provides evidence for **fairness, governance, and transparency**. The policy document details a formal AI Ethics governance process that guides the development of all AI features, including proprietary and third-party models, ensuring they are vetted for compliance and undergo operational testing to mitigate bias and harmful outcomes. Furthermore, it commits to transparency through content credentials for provenance and authenticity, and outlines mechanisms for bias remediation and feedback.",
          "title": "Generative AI Built for Business",
          "url": "https://adobe.com/cc-shared/assets/pdf/trust-center/ungated/whitepapers/corporate/adobe-gen-ai-built-for-business-solution-brief.pdf"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_012",
          "source_tier": "company_owned",
          "summary": "This policy document, \"Responsible AI adoption framework | The AI inflection point guide,\" provides evidence for **governance**, **external accountability**, **fairness**, and **transparency**. It details the establishment and empowerment of governance teams, vendor evaluation, and adherence to external regulatory frameworks like NIST and the EU AI Act, supporting governance and external accountability. Furthermore, the document describes testing for bias in AI products and the operational use of content filters, demonstrating efforts towards fairness and transparency.",
          "title": "Responsible AI adoption framework | The AI inflection point guide",
          "url": "https://business.adobe.com/resources/sdk/the-ai-inflection-point.html"
        },
        {
          "artifact_type": "technical_paper",
          "source_id": "src_017",
          "source_tier": "third_party",
          "summary": "This technical paper on Adobe's AI approach provides evidence for **external_accountability**, **fairness**, **governance**, **oversight**, **privacy**, and **transparency**. It supports **external_accountability** through indemnification policies for enterprise users and a commitment to legally licensed training data. **Governance** is evidenced by mentions of AI governance training, AI architect designations, and formal AI policies. The paper also touches on **transparency** by discussing the need for clarity in generative AI pricing and capabilities, and **oversight** is implied through the evolution of reviewers to validators for AI outputs. While not explicitly detailed, the focus on legally grounded training data and secure procurement processes suggests considerations for **privacy**.",
          "title": "Adobe's Legally Grounded AI Model Offers a Blueprint for Responsible Innovation",
          "url": "https://complexdiscovery.com/adobes-legally-grounded-ai-model-offers-a-blueprint-for-responsible-innovation"
        }
      ],
      "score": 2,
      "source_count": 8
    },
    "governance": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Governance & Accountability",
      "evidence_count": 121,
      "findings": "Adobe outlines specific governance processes, including a pre-market evaluation process for new AI features guided by accountability and responsibility principles. The company details a formal AI Ethics governance process that guides AI feature development, ensuring compliance vetting and adherence to external regulatory frameworks. Governance practices also include a structured review process with specific roles, AI governance training, AI architect designations, and formal AI policies.",
      "max_score": 2,
      "path_to_improvement": null,
      "relevant_sources": [
        {
          "artifact_type": "policy",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This company-owned policy document, \"Responsible AI & Ethical Development - Adobe for Business,\" provides evidence for **external_accountability, fairness, governance, and oversight**. The policy outlines specific mechanisms such as establishing governance processes, requiring AI Impact Assessments to identify harmful biases, and creating a diverse AI Ethics Review Board for oversight, all of which demonstrate a commitment to responsible AI development and deployment. The document also explicitly lists training, testing, impact assessments, and diverse human oversight as key pillars, further supporting these responsible AI principles.",
          "title": "Responsible AI & Ethical Development - Adobe for Business",
          "url": "https://business.adobe.com/ai/responsible-ai.html"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_002",
          "source_tier": "company_owned",
          "summary": "This policy document, \"Our Commitment to AI Ethics - Adobe,\" provides evidence for the **fairness** and **governance** pillars of responsible AI. It supports fairness by focusing on evaluating AI impact, inclusiveness, and assessing bias. The document demonstrates strong governance through its detailed operational processes, including AI Impact Assessments, an AI Ethics Review Board, assigned accountability for AI ethics to leaders, and proactive harm mitigation strategies.",
          "title": "Our Commitment to AI Ethics - Adobe",
          "url": "https://adobe.com/cc-shared/assets/pdf/ai-ethics/adobe-ai-ethics-principles.pdf"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_004",
          "source_tier": "company_owned",
          "summary": "This Adobe blog post provides evidence for the **governance** and **transparency** pillars of responsible AI. The post details how Adobe's five-year evolution of its AI Ethics framework, built on principles of accountability, responsibility, and transparency, has become foundational to AI development. It highlights the embedding of this framework, the use of AI Ethics principles as actionable guidelines, and the development of an evaluation framework for responsible AI, all of which demonstrate a commitment to governance. Furthermore, the blog post explicitly mentions transparency as a core principle and a key governance mechanism.",
          "title": "Reflecting on our five-year journey with our AI Ethics principles",
          "url": "https://blog.adobe.com/en/publish/2024/10/14/reflecting-our-five-year-journey-with-our-ai-ethics-principles"
        },
        {
          "artifact_type": "sec_filing",
          "source_id": "src_005",
          "source_tier": "authority",
          "summary": "This 2024 Annual Report (Form 10-K) provides evidence for **governance**, **transparency**, **external accountability**, and **fairness**. The report details Adobe's AI offerings like Acrobat AI Assistant and Adobe Firefly Services, indicating transparency in their capabilities and use cases. It also references a commitment to AI Ethics principles, including accountability and responsibility, and discusses AI regulations and compliance, supporting external accountability. Furthermore, the report mentions concerns about \"harmful bias\" and a commitment to \"product equity,\" demonstrating attention to fairness.",
          "title": "FORM 10-K ADOBE INC. - 2024 Annual Report",
          "url": "https://sec.gov/Archives/edgar/data/796343/000079634325000050/adbe2024annualreporta.pdf"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_006",
          "source_tier": "company_owned",
          "summary": "This policy document, \"Responsible AI - Adobe,\" provides evidence for the **governance** and **transparency** pillars of responsible AI. It supports governance by outlining a pre-market evaluation process for all new AI features, guided by principles of accountability and responsibility. Transparency is supported through descriptions of AI/ML use cases, integration, and the capabilities of generative AI, implying a commitment to making AI systems and their functions clear.",
          "title": "Responsible AI - Adobe",
          "url": "https://adobe.com/trust/responsible-ai.html"
        },
        {
          "artifact_type": "technical_paper",
          "source_id": "src_007",
          "source_tier": "third_party",
          "summary": "This technical paper from Adobe details their adversarial testing process and a three-tiered human impact assessment framework for mitigating biased and harmful generative AI outputs. The paper provides evidence for **fairness** by describing debiasing efforts, bias reduction, and ensuring diverse representation, as well as for **governance** and **oversight** through its structured approach to assessing and mitigating AI impact before product release, including specific feedback mechanisms and operational safety mechanisms like red teaming.",
          "title": "Reducing biased and harmful outcomes in generative AI",
          "url": "https://adobe.design/stories/leading-design/reducing-biased-and-harmful-outcomes-in-generative-ai"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_008",
          "source_tier": "company_owned",
          "summary": "This Adobe infographic, a company-owned policy document, details a robust AI Ethics governance process involving three institutional bodies: the AI Ethics Committee, AI Ethics Review Board, and AI@Adobe Working Group. The document supports **governance** and **oversight** by outlining a structured review process with specific roles and responsibilities for these bodies, including submission, collaboration, risk mitigation, and repetition. Evidence for **fairness** is found in the mention of conducting testing to reduce bias and harmful outcomes, while the emphasis on AI ethics principles like accountability, responsibility, and transparency, alongside a standardized process, supports the **transparency** pillar.",
          "title": "Building responsible generative AI solutions for the new creative era",
          "url": "https://business.adobe.com/assets/pdfs/resources/infographics/responsible-gen-ai-infographic/building-responsible-generative-ai-solutions-for-the-new-creative-era.pdf"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_009",
          "source_tier": "company_owned",
          "summary": "This Adobe blog post provides evidence for the **governance** and **transparency** pillars of responsible AI. It details the company's mandatory AI Impact Assessment process and AI Ethics Review Board, demonstrating robust governance. Furthermore, the post highlights commitments to watermarking and provenance for AI-generated content, along with ongoing testing and sharing of best practices, which support transparency.",
          "title": "Building safe, secure and trustworthy AI: Adobe's commitments to customers and community",
          "url": "https://blog.adobe.com/en/publish/2023/09/12/adobes-ai-commitments-to-customers-and-community"
        },
        {
          "artifact_type": "technical_paper",
          "source_id": "src_010",
          "source_tier": "third_party",
          "summary": "This technical paper on Adobe's Responsible AI risk management describes a context-driven approach that supports the **governance** and **oversight** pillars. The paper details a framework for segmenting AI features into low- and high-impact categories, implying a structured governance approach to risk. Furthermore, it highlights human oversight and accountability mechanisms embedded within AI pipelines, demonstrating operational execution for oversight. The source also provides evidence for the **transparency** pillar through its mention of AI Ethics Impact Assessments.",
          "title": "Adobe's Context-Driven Approach to Responsible AI Risk Management",
          "url": "https://opendatascience.com/adobes-context-driven-approach-to-responsible-ai-risk-management"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_011",
          "source_tier": "company_owned",
          "summary": "This Adobe solution brief, \"Generative AI Built for Business,\" provides evidence for **fairness, governance, and transparency**. The policy document details a formal AI Ethics governance process that guides the development of all AI features, including proprietary and third-party models, ensuring they are vetted for compliance and undergo operational testing to mitigate bias and harmful outcomes. Furthermore, it commits to transparency through content credentials for provenance and authenticity, and outlines mechanisms for bias remediation and feedback.",
          "title": "Generative AI Built for Business",
          "url": "https://adobe.com/cc-shared/assets/pdf/trust-center/ungated/whitepapers/corporate/adobe-gen-ai-built-for-business-solution-brief.pdf"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_012",
          "source_tier": "company_owned",
          "summary": "This policy document, \"Responsible AI adoption framework | The AI inflection point guide,\" provides evidence for **governance**, **external accountability**, **fairness**, and **transparency**. It details the establishment and empowerment of governance teams, vendor evaluation, and adherence to external regulatory frameworks like NIST and the EU AI Act, supporting governance and external accountability. Furthermore, the document describes testing for bias in AI products and the operational use of content filters, demonstrating efforts towards fairness and transparency.",
          "title": "Responsible AI adoption framework | The AI inflection point guide",
          "url": "https://business.adobe.com/resources/sdk/the-ai-inflection-point.html"
        },
        {
          "artifact_type": "help_page",
          "source_id": "src_013",
          "source_tier": "company_owned",
          "summary": "This Adobe help page provides evidence for **governance**, **oversight**, and **transparency**. It supports transparency by disclosing AI capabilities and potential inaccuracies, informing users about system limitations. The page also demonstrates oversight and governance through its description of an ongoing feedback mechanism for AI improvement and by explaining AI functionality while acknowledging limitations.",
          "title": "Adobe generative AI user disclosures",
          "url": "https://helpx.adobe.com/acrobat/desktop/use-acrobat-ai/understand-usage-policies/user-disclosures.html"
        },
        {
          "artifact_type": "press_release",
          "source_id": "src_015",
          "source_tier": "third_party",
          "summary": "This Wired report provides evidence for the **governance**, **privacy**, and **transparency** pillars. It highlights Adobe's stated commitment not to use user content for training Firefly, supporting the **privacy** pillar by indicating policy commitments around data usage. The report also touches on the ethical training of AI and rights management, offering some insight into **governance**, while mentioning \"automated methods\" and \"machine learning\" for service improvement, which implies data access and usage policies relevant to **transparency**.",
          "title": "Adobe Says It Won't Train AI Using Artists' Work. Creatives Aren't Convinced",
          "url": "https://wired.com/story/adobe-says-it-wont-train-ai-using-artists-work-creatives-arent-convinced"
        },
        {
          "artifact_type": "other",
          "source_id": "src_016",
          "source_tier": "third_party",
          "summary": "This MarTech report, based on a Bloomberg investigation, provides evidence for **external_accountability**, **governance**, and **transparency**. It supports external_accountability and governance by discussing Adobe's legal indemnification for AI-generated content, which aims to ensure commercial safety. The report also highlights transparency concerns, referencing regulatory requirements like the AI Act for model training data and customer apprehension about generative AI training data composition.",
          "title": "Legal risks loom for Firefly users after Adobe's AI image tool training exposed",
          "url": "https://martech.org/legal-risks-loom-for-firefly-users-after-adobes-ai-image-tool-training-exposed"
        },
        {
          "artifact_type": "technical_paper",
          "source_id": "src_017",
          "source_tier": "third_party",
          "summary": "This technical paper on Adobe's AI approach provides evidence for **external_accountability**, **fairness**, **governance**, **oversight**, **privacy**, and **transparency**. It supports **external_accountability** through indemnification policies for enterprise users and a commitment to legally licensed training data. **Governance** is evidenced by mentions of AI governance training, AI architect designations, and formal AI policies. The paper also touches on **transparency** by discussing the need for clarity in generative AI pricing and capabilities, and **oversight** is implied through the evolution of reviewers to validators for AI outputs. While not explicitly detailed, the focus on legally grounded training data and secure procurement processes suggests considerations for **privacy**.",
          "title": "Adobe's Legally Grounded AI Model Offers a Blueprint for Responsible Innovation",
          "url": "https://complexdiscovery.com/adobes-legally-grounded-ai-model-offers-a-blueprint-for-responsible-innovation"
        }
      ],
      "score": 2,
      "source_count": 15
    },
    "oversight": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Human Oversight & Accountability",
      "evidence_count": 13,
      "findings": "Adobe's policy documents create a diverse AI Ethics Review Board and explicitly list diverse human oversight as a key pillar. User guidelines instruct users to review and validate AI outputs, mentioning automated and manual review methods for abuse prevention. Technical papers describe a structured approach to assessing and mitigating AI impact, highlighting human oversight and accountability mechanisms embedded within AI pipelines, and implying oversight through the evolution of reviewers to validators for AI outputs.",
      "max_score": 2,
      "path_to_improvement": null,
      "relevant_sources": [
        {
          "artifact_type": "policy",
          "source_id": "src_001",
          "source_tier": "company_owned",
          "summary": "This company-owned policy document, \"Responsible AI & Ethical Development - Adobe for Business,\" provides evidence for **external_accountability, fairness, governance, and oversight**. The policy outlines specific mechanisms such as establishing governance processes, requiring AI Impact Assessments to identify harmful biases, and creating a diverse AI Ethics Review Board for oversight, all of which demonstrate a commitment to responsible AI development and deployment. The document also explicitly lists training, testing, impact assessments, and diverse human oversight as key pillars, further supporting these responsible AI principles.",
          "title": "Responsible AI & Ethical Development - Adobe for Business",
          "url": "https://business.adobe.com/ai/responsible-ai.html"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_003",
          "source_tier": "company_owned",
          "summary": "This policy document, \"Adobe Generative AI User Guidelines,\" provides evidence for the **oversight** and **transparency** pillars of responsible AI. It supports oversight by instructing users to review and validate AI outputs, implying human oversight is required, and by mentioning the review of AI-generated content through automated and manual methods for abuse prevention. The document also supports transparency by stating an intent to label AI-generated content, indicating a policy for disclosure.",
          "title": "Adobe Generative AI User Guidelines",
          "url": "https://adobe.com/legal/licenses-terms/adobe-gen-ai-user-guidelines.html"
        },
        {
          "artifact_type": "technical_paper",
          "source_id": "src_007",
          "source_tier": "third_party",
          "summary": "This technical paper from Adobe details their adversarial testing process and a three-tiered human impact assessment framework for mitigating biased and harmful generative AI outputs. The paper provides evidence for **fairness** by describing debiasing efforts, bias reduction, and ensuring diverse representation, as well as for **governance** and **oversight** through its structured approach to assessing and mitigating AI impact before product release, including specific feedback mechanisms and operational safety mechanisms like red teaming.",
          "title": "Reducing biased and harmful outcomes in generative AI",
          "url": "https://adobe.design/stories/leading-design/reducing-biased-and-harmful-outcomes-in-generative-ai"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_008",
          "source_tier": "company_owned",
          "summary": "This Adobe infographic, a company-owned policy document, details a robust AI Ethics governance process involving three institutional bodies: the AI Ethics Committee, AI Ethics Review Board, and AI@Adobe Working Group. The document supports **governance** and **oversight** by outlining a structured review process with specific roles and responsibilities for these bodies, including submission, collaboration, risk mitigation, and repetition. Evidence for **fairness** is found in the mention of conducting testing to reduce bias and harmful outcomes, while the emphasis on AI ethics principles like accountability, responsibility, and transparency, alongside a standardized process, supports the **transparency** pillar.",
          "title": "Building responsible generative AI solutions for the new creative era",
          "url": "https://business.adobe.com/assets/pdfs/resources/infographics/responsible-gen-ai-infographic/building-responsible-generative-ai-solutions-for-the-new-creative-era.pdf"
        },
        {
          "artifact_type": "technical_paper",
          "source_id": "src_010",
          "source_tier": "third_party",
          "summary": "This technical paper on Adobe's Responsible AI risk management describes a context-driven approach that supports the **governance** and **oversight** pillars. The paper details a framework for segmenting AI features into low- and high-impact categories, implying a structured governance approach to risk. Furthermore, it highlights human oversight and accountability mechanisms embedded within AI pipelines, demonstrating operational execution for oversight. The source also provides evidence for the **transparency** pillar through its mention of AI Ethics Impact Assessments.",
          "title": "Adobe's Context-Driven Approach to Responsible AI Risk Management",
          "url": "https://opendatascience.com/adobes-context-driven-approach-to-responsible-ai-risk-management"
        },
        {
          "artifact_type": "help_page",
          "source_id": "src_013",
          "source_tier": "company_owned",
          "summary": "This Adobe help page provides evidence for **governance**, **oversight**, and **transparency**. It supports transparency by disclosing AI capabilities and potential inaccuracies, informing users about system limitations. The page also demonstrates oversight and governance through its description of an ongoing feedback mechanism for AI improvement and by explaining AI functionality while acknowledging limitations.",
          "title": "Adobe generative AI user disclosures",
          "url": "https://helpx.adobe.com/acrobat/desktop/use-acrobat-ai/understand-usage-policies/user-disclosures.html"
        },
        {
          "artifact_type": "technical_paper",
          "source_id": "src_017",
          "source_tier": "third_party",
          "summary": "This technical paper on Adobe's AI approach provides evidence for **external_accountability**, **fairness**, **governance**, **oversight**, **privacy**, and **transparency**. It supports **external_accountability** through indemnification policies for enterprise users and a commitment to legally licensed training data. **Governance** is evidenced by mentions of AI governance training, AI architect designations, and formal AI policies. The paper also touches on **transparency** by discussing the need for clarity in generative AI pricing and capabilities, and **oversight** is implied through the evolution of reviewers to validators for AI outputs. While not explicitly detailed, the focus on legally grounded training data and secure procurement processes suggests considerations for **privacy**.",
          "title": "Adobe's Legally Grounded AI Model Offers a Blueprint for Responsible Innovation",
          "url": "https://complexdiscovery.com/adobes-legally-grounded-ai-model-offers-a-blueprint-for-responsible-innovation"
        }
      ],
      "score": 2,
      "source_count": 7
    },
    "privacy": {
      "best_evidence_type": "POLICY",
      "display_name": "Privacy & Security",
      "evidence_count": 4,
      "findings": "Reports highlight Adobe's stated commitment not to use user content for training Firefly, indicating policy commitments around data usage. Technical papers suggest considerations for privacy through a focus on legally grounded training data and secure procurement processes.",
      "max_score": 2,
      "path_to_improvement": "Publish AI-specific privacy impact assessments or data handling procedures.",
      "relevant_sources": [
        {
          "artifact_type": "sec_filing",
          "source_id": "src_005",
          "source_tier": "authority",
          "summary": "This 2024 Annual Report (Form 10-K) provides evidence for **governance**, **transparency**, **external accountability**, and **fairness**. The report details Adobe's AI offerings like Acrobat AI Assistant and Adobe Firefly Services, indicating transparency in their capabilities and use cases. It also references a commitment to AI Ethics principles, including accountability and responsibility, and discusses AI regulations and compliance, supporting external accountability. Furthermore, the report mentions concerns about \"harmful bias\" and a commitment to \"product equity,\" demonstrating attention to fairness.",
          "title": "FORM 10-K ADOBE INC. - 2024 Annual Report",
          "url": "https://sec.gov/Archives/edgar/data/796343/000079634325000050/adbe2024annualreporta.pdf"
        },
        {
          "artifact_type": "press_release",
          "source_id": "src_015",
          "source_tier": "third_party",
          "summary": "This Wired report provides evidence for the **governance**, **privacy**, and **transparency** pillars. It highlights Adobe's stated commitment not to use user content for training Firefly, supporting the **privacy** pillar by indicating policy commitments around data usage. The report also touches on the ethical training of AI and rights management, offering some insight into **governance**, while mentioning \"automated methods\" and \"machine learning\" for service improvement, which implies data access and usage policies relevant to **transparency**.",
          "title": "Adobe Says It Won't Train AI Using Artists' Work. Creatives Aren't Convinced",
          "url": "https://wired.com/story/adobe-says-it-wont-train-ai-using-artists-work-creatives-arent-convinced"
        },
        {
          "artifact_type": "technical_paper",
          "source_id": "src_017",
          "source_tier": "third_party",
          "summary": "This technical paper on Adobe's AI approach provides evidence for **external_accountability**, **fairness**, **governance**, **oversight**, **privacy**, and **transparency**. It supports **external_accountability** through indemnification policies for enterprise users and a commitment to legally licensed training data. **Governance** is evidenced by mentions of AI governance training, AI architect designations, and formal AI policies. The paper also touches on **transparency** by discussing the need for clarity in generative AI pricing and capabilities, and **oversight** is implied through the evolution of reviewers to validators for AI outputs. While not explicitly detailed, the focus on legally grounded training data and secure procurement processes suggests considerations for **privacy**.",
          "title": "Adobe's Legally Grounded AI Model Offers a Blueprint for Responsible Innovation",
          "url": "https://complexdiscovery.com/adobes-legally-grounded-ai-model-offers-a-blueprint-for-responsible-innovation"
        }
      ],
      "score": 1,
      "source_count": 3
    },
    "transparency": {
      "best_evidence_type": "OPERATIONAL",
      "display_name": "Transparency",
      "evidence_count": 75,
      "findings": "Adobe's policy documents state an intent to label AI-generated content and indicate a policy for disclosure, emphasizing transparency as a core principle. Reports detail AI offerings and their capabilities, while commitments to watermarking, provenance, and content credentials for authenticity are highlighted. Adobe also discloses AI capabilities, potential inaccuracies, and system limitations to users, and references regulatory requirements for model training data.",
      "max_score": 2,
      "path_to_improvement": null,
      "relevant_sources": [
        {
          "artifact_type": "policy",
          "source_id": "src_003",
          "source_tier": "company_owned",
          "summary": "This policy document, \"Adobe Generative AI User Guidelines,\" provides evidence for the **oversight** and **transparency** pillars of responsible AI. It supports oversight by instructing users to review and validate AI outputs, implying human oversight is required, and by mentioning the review of AI-generated content through automated and manual methods for abuse prevention. The document also supports transparency by stating an intent to label AI-generated content, indicating a policy for disclosure.",
          "title": "Adobe Generative AI User Guidelines",
          "url": "https://adobe.com/legal/licenses-terms/adobe-gen-ai-user-guidelines.html"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_004",
          "source_tier": "company_owned",
          "summary": "This Adobe blog post provides evidence for the **governance** and **transparency** pillars of responsible AI. The post details how Adobe's five-year evolution of its AI Ethics framework, built on principles of accountability, responsibility, and transparency, has become foundational to AI development. It highlights the embedding of this framework, the use of AI Ethics principles as actionable guidelines, and the development of an evaluation framework for responsible AI, all of which demonstrate a commitment to governance. Furthermore, the blog post explicitly mentions transparency as a core principle and a key governance mechanism.",
          "title": "Reflecting on our five-year journey with our AI Ethics principles",
          "url": "https://blog.adobe.com/en/publish/2024/10/14/reflecting-our-five-year-journey-with-our-ai-ethics-principles"
        },
        {
          "artifact_type": "sec_filing",
          "source_id": "src_005",
          "source_tier": "authority",
          "summary": "This 2024 Annual Report (Form 10-K) provides evidence for **governance**, **transparency**, **external accountability**, and **fairness**. The report details Adobe's AI offerings like Acrobat AI Assistant and Adobe Firefly Services, indicating transparency in their capabilities and use cases. It also references a commitment to AI Ethics principles, including accountability and responsibility, and discusses AI regulations and compliance, supporting external accountability. Furthermore, the report mentions concerns about \"harmful bias\" and a commitment to \"product equity,\" demonstrating attention to fairness.",
          "title": "FORM 10-K ADOBE INC. - 2024 Annual Report",
          "url": "https://sec.gov/Archives/edgar/data/796343/000079634325000050/adbe2024annualreporta.pdf"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_006",
          "source_tier": "company_owned",
          "summary": "This policy document, \"Responsible AI - Adobe,\" provides evidence for the **governance** and **transparency** pillars of responsible AI. It supports governance by outlining a pre-market evaluation process for all new AI features, guided by principles of accountability and responsibility. Transparency is supported through descriptions of AI/ML use cases, integration, and the capabilities of generative AI, implying a commitment to making AI systems and their functions clear.",
          "title": "Responsible AI - Adobe",
          "url": "https://adobe.com/trust/responsible-ai.html"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_008",
          "source_tier": "company_owned",
          "summary": "This Adobe infographic, a company-owned policy document, details a robust AI Ethics governance process involving three institutional bodies: the AI Ethics Committee, AI Ethics Review Board, and AI@Adobe Working Group. The document supports **governance** and **oversight** by outlining a structured review process with specific roles and responsibilities for these bodies, including submission, collaboration, risk mitigation, and repetition. Evidence for **fairness** is found in the mention of conducting testing to reduce bias and harmful outcomes, while the emphasis on AI ethics principles like accountability, responsibility, and transparency, alongside a standardized process, supports the **transparency** pillar.",
          "title": "Building responsible generative AI solutions for the new creative era",
          "url": "https://business.adobe.com/assets/pdfs/resources/infographics/responsible-gen-ai-infographic/building-responsible-generative-ai-solutions-for-the-new-creative-era.pdf"
        },
        {
          "artifact_type": "blog_post",
          "source_id": "src_009",
          "source_tier": "company_owned",
          "summary": "This Adobe blog post provides evidence for the **governance** and **transparency** pillars of responsible AI. It details the company's mandatory AI Impact Assessment process and AI Ethics Review Board, demonstrating robust governance. Furthermore, the post highlights commitments to watermarking and provenance for AI-generated content, along with ongoing testing and sharing of best practices, which support transparency.",
          "title": "Building safe, secure and trustworthy AI: Adobe's commitments to customers and community",
          "url": "https://blog.adobe.com/en/publish/2023/09/12/adobes-ai-commitments-to-customers-and-community"
        },
        {
          "artifact_type": "technical_paper",
          "source_id": "src_010",
          "source_tier": "third_party",
          "summary": "This technical paper on Adobe's Responsible AI risk management describes a context-driven approach that supports the **governance** and **oversight** pillars. The paper details a framework for segmenting AI features into low- and high-impact categories, implying a structured governance approach to risk. Furthermore, it highlights human oversight and accountability mechanisms embedded within AI pipelines, demonstrating operational execution for oversight. The source also provides evidence for the **transparency** pillar through its mention of AI Ethics Impact Assessments.",
          "title": "Adobe's Context-Driven Approach to Responsible AI Risk Management",
          "url": "https://opendatascience.com/adobes-context-driven-approach-to-responsible-ai-risk-management"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_011",
          "source_tier": "company_owned",
          "summary": "This Adobe solution brief, \"Generative AI Built for Business,\" provides evidence for **fairness, governance, and transparency**. The policy document details a formal AI Ethics governance process that guides the development of all AI features, including proprietary and third-party models, ensuring they are vetted for compliance and undergo operational testing to mitigate bias and harmful outcomes. Furthermore, it commits to transparency through content credentials for provenance and authenticity, and outlines mechanisms for bias remediation and feedback.",
          "title": "Generative AI Built for Business",
          "url": "https://adobe.com/cc-shared/assets/pdf/trust-center/ungated/whitepapers/corporate/adobe-gen-ai-built-for-business-solution-brief.pdf"
        },
        {
          "artifact_type": "policy",
          "source_id": "src_012",
          "source_tier": "company_owned",
          "summary": "This policy document, \"Responsible AI adoption framework | The AI inflection point guide,\" provides evidence for **governance**, **external accountability**, **fairness**, and **transparency**. It details the establishment and empowerment of governance teams, vendor evaluation, and adherence to external regulatory frameworks like NIST and the EU AI Act, supporting governance and external accountability. Furthermore, the document describes testing for bias in AI products and the operational use of content filters, demonstrating efforts towards fairness and transparency.",
          "title": "Responsible AI adoption framework | The AI inflection point guide",
          "url": "https://business.adobe.com/resources/sdk/the-ai-inflection-point.html"
        },
        {
          "artifact_type": "help_page",
          "source_id": "src_013",
          "source_tier": "company_owned",
          "summary": "This Adobe help page provides evidence for **governance**, **oversight**, and **transparency**. It supports transparency by disclosing AI capabilities and potential inaccuracies, informing users about system limitations. The page also demonstrates oversight and governance through its description of an ongoing feedback mechanism for AI improvement and by explaining AI functionality while acknowledging limitations.",
          "title": "Adobe generative AI user disclosures",
          "url": "https://helpx.adobe.com/acrobat/desktop/use-acrobat-ai/understand-usage-policies/user-disclosures.html"
        },
        {
          "artifact_type": "press_release",
          "source_id": "src_015",
          "source_tier": "third_party",
          "summary": "This Wired report provides evidence for the **governance**, **privacy**, and **transparency** pillars. It highlights Adobe's stated commitment not to use user content for training Firefly, supporting the **privacy** pillar by indicating policy commitments around data usage. The report also touches on the ethical training of AI and rights management, offering some insight into **governance**, while mentioning \"automated methods\" and \"machine learning\" for service improvement, which implies data access and usage policies relevant to **transparency**.",
          "title": "Adobe Says It Won't Train AI Using Artists' Work. Creatives Aren't Convinced",
          "url": "https://wired.com/story/adobe-says-it-wont-train-ai-using-artists-work-creatives-arent-convinced"
        },
        {
          "artifact_type": "other",
          "source_id": "src_016",
          "source_tier": "third_party",
          "summary": "This MarTech report, based on a Bloomberg investigation, provides evidence for **external_accountability**, **governance**, and **transparency**. It supports external_accountability and governance by discussing Adobe's legal indemnification for AI-generated content, which aims to ensure commercial safety. The report also highlights transparency concerns, referencing regulatory requirements like the AI Act for model training data and customer apprehension about generative AI training data composition.",
          "title": "Legal risks loom for Firefly users after Adobe's AI image tool training exposed",
          "url": "https://martech.org/legal-risks-loom-for-firefly-users-after-adobes-ai-image-tool-training-exposed"
        },
        {
          "artifact_type": "technical_paper",
          "source_id": "src_017",
          "source_tier": "third_party",
          "summary": "This technical paper on Adobe's AI approach provides evidence for **external_accountability**, **fairness**, **governance**, **oversight**, **privacy**, and **transparency**. It supports **external_accountability** through indemnification policies for enterprise users and a commitment to legally licensed training data. **Governance** is evidenced by mentions of AI governance training, AI architect designations, and formal AI policies. The paper also touches on **transparency** by discussing the need for clarity in generative AI pricing and capabilities, and **oversight** is implied through the evolution of reviewers to validators for AI outputs. While not explicitly detailed, the focus on legally grounded training data and secure procurement processes suggests considerations for **privacy**.",
          "title": "Adobe's Legally Grounded AI Model Offers a Blueprint for Responsible Innovation",
          "url": "https://complexdiscovery.com/adobes-legally-grounded-ai-model-offers-a-blueprint-for-responsible-innovation"
        }
      ],
      "score": 2,
      "source_count": 13
    }
  },
  "published_at": "2026-02-23T21:41:38Z",
  "run_id": "20260218_042128_efcb",
  "schema_version": "1.0",
  "summary": {
    "key_gaps": [
      "Explainability"
    ],
    "key_strengths": [
      "Transparency",
      "Fairness & Bias Mitigation",
      "Human Oversight & Accountability",
      "Governance & Accountability",
      "Public Commitments & External Audits"
    ],
    "overall_findings": "Adobe's policy documents state an intent to label AI-generated content, addressing transparency at an operational level. This is part of the 6 of 7 responsible AI pillars for which documented evidence was found, drawing from 22 publicly available sources. Further operational practices include policy requirements for AI Impact Assessments to identify harmful biases under fairness, and the creation of a diverse AI Ethics Review Board for oversight. Additionally, privacy is addressed at the policy level, with reports highlighting a stated commitment not to use user content for training Firefly. No qualifying public evidence was found for explainability.",
    "pillars_operational": 5,
    "pillars_policy_only": 1,
    "pillars_with_evidence": 6,
    "pillars_without_evidence": 1,
    "total_evidence_items": 167,
    "total_sources_used": 16
  }
}
